{
  "metadata": {
    "topic": "Stream processing frameworks",
    "generated_at": "2025-10-29T15:55:06.642142",
    "repositories_analyzed": 15,
    "total_features": 419,
    "unique_features": 340,
    "deduplication_rate": 0.1885441527446301
  },
  "repositories": [
    {
      "name": "pathwaycom/pathway",
      "url": "https://github.com/pathwaycom/pathway",
      "stars": 48864,
      "language": "Python",
      "features": [
        {
          "text": "A wide range of connectors: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.",
          "source_url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        },
        {
          "text": "Stateless and stateful transformations: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.",
          "source_url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "text": "Persistence: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!",
          "source_url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        },
        {
          "text": "Consistency: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency.",
          "source_url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "text": "Scalable Rust engine: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.",
          "source_url": "https://github.com/pathwaycom/pathway#L97",
          "evidence": "- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations."
        },
        {
          "text": "LLM helpers: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.",
          "source_url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        },
        {
          "text": "allowing you to seamlessly integrate your favorite python ml libraries",
          "source_url": "https://github.com/pathwaycom/pathway#L46",
          "evidence": "Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries."
        },
        {
          "text": "integrate your favorite python ml libraries",
          "source_url": "https://github.com/pathwaycom/pathway#L46",
          "evidence": "Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries."
        },
        {
          "text": "processing data streams",
          "source_url": "https://github.com/pathwaycom/pathway#L48",
          "evidence": "The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams."
        },
        {
          "text": "performs incremental computation",
          "source_url": "https://github.com/pathwaycom/pathway#L50",
          "evidence": "Pathway is powered by a **scalable Rust engine** based on Differential Dataflow and performs incremental computation."
        },
        {
          "text": "run by the rust engine, enabling multithreading, multiprocessing, and distributed computations",
          "source_url": "https://github.com/pathwaycom/pathway#L51",
          "evidence": "Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations."
        },
        {
          "text": "run examples](https://pathway",
          "source_url": "https://github.com/pathwaycom/pathway#L65",
          "evidence": "[Try one of our easy-to-run examples](https://pathway.com/developers/templates)!"
        },
        {
          "text": "processing and real-time analytics pipelines",
          "source_url": "https://github.com/pathwaycom/pathway#L69",
          "evidence": "### Event processing and real-time analytics pipelines"
        },
        {
          "text": "processing as easy as possible",
          "source_url": "https://github.com/pathwaycom/pathway#L70",
          "evidence": "With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:"
        },
        {
          "text": "processing pipelines, including:",
          "source_url": "https://github.com/pathwaycom/pathway#L70",
          "evidence": "With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:"
        },
        {
          "text": "provides dedicated llm tooling to build live llm and rag pipelines",
          "source_url": "https://github.com/pathwaycom/pathway#L81",
          "evidence": "Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview)."
        },
        {
          "text": "build live llm and rag pipelines",
          "source_url": "https://github.com/pathwaycom/pathway#L81",
          "evidence": "Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview)."
        },
        {
          "text": "allows you to connect to more than 300 different data sources",
          "source_url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        },
        {
          "text": "build your own custom connector using pathway python connector",
          "source_url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        },
        {
          "text": "supports stateful transformations such as joins, windowing, and sorting",
          "source_url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "text": "provides many transformations directly implemented in rust",
          "source_url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "text": "implement your own or you can use any python library to process your data",
          "source_url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "text": "process your data",
          "source_url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "text": "provides persistence to save the state of the computation",
          "source_url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        },
        {
          "text": "allows you to restart your pipeline after an update or a crash",
          "source_url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        },
        {
          "text": "provides the \"exactly once\" consistency",
          "source_url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "text": "handles the time for you, making sure all your computations are consistent",
          "source_url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "text": "manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system",
          "source_url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "text": "provides an llm extension with all the utilities to integrate llms with your data pipelines (llm wrappers, parsers, embedders, splitters), including an in-memory real-time vector index, and integrations with llamaindex and langchain",
          "source_url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        },
        {
          "text": "integrate llms with your data pipelines (llm wrappers, parsers, embedders, splitters), including an in-memory real-time vector index, and integrations with llamaindex and langchain",
          "source_url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        },
        {
          "text": "build and deploy rag applications with your live documents",
          "source_url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        },
        {
          "text": "run pathway on a virtual machine",
          "source_url": "https://github.com/pathwaycom/pathway#L113",
          "evidence": "\u26a0\ufe0f Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine."
        },
        {
          "text": "import pathway as pw",
          "source_url": "https://github.com/pathwaycom/pathway#L119",
          "evidence": "import pathway as pw"
        },
        {
          "text": "run the computation",
          "source_url": "https://github.com/pathwaycom/pathway#L140",
          "evidence": "# Run the computation"
        },
        {
          "text": "run pathway [in google colab](https://colab",
          "source_url": "https://github.com/pathwaycom/pathway#L144",
          "evidence": "Run Pathway [in Google Colab](https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing)."
        },
        {
          "text": "import pathway as pw",
          "source_url": "https://github.com/pathwaycom/pathway#L156",
          "evidence": "import pathway as pw"
        },
        {
          "text": "handle the updates",
          "source_url": "https://github.com/pathwaycom/pathway#L159",
          "evidence": "Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:"
        },
        {
          "text": "processing pipeline, and let pathway handle the updates",
          "source_url": "https://github.com/pathwaycom/pathway#L159",
          "evidence": "Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:"
        },
        {
          "text": "create your processing pipeline, and let pathway handle the updates",
          "source_url": "https://github.com/pathwaycom/pathway#L159",
          "evidence": "Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:"
        },
        {
          "text": "run your pathway project (say, `main",
          "source_url": "https://github.com/pathwaycom/pathway#L165",
          "evidence": "You can then run your Pathway project (say, `main.py`) just like a normal Python script: `$ python main.py`."
        },
        {
          "text": "allows you to keep track of the number of messages sent by each connector and the latency of the system",
          "source_url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        },
        {
          "text": "includes log messages",
          "source_url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        },
        {
          "text": "monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system",
          "source_url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        },
        {
          "text": "track of the number of messages sent by each connector and the latency of the system",
          "source_url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        },
        {
          "text": "supports multithreading",
          "source_url": "https://github.com/pathwaycom/pathway#L176",
          "evidence": "Pathway natively supports multithreading."
        },
        {
          "text": "run pathway using docker",
          "source_url": "https://github.com/pathwaycom/pathway#L187",
          "evidence": "You can easily run Pathway using docker."
        },
        {
          "text": "run pip install --no-cache-dir -r requirements",
          "source_url": "https://github.com/pathwaycom/pathway#L199",
          "evidence": "RUN pip install --no-cache-dir -r requirements.txt"
        },
        {
          "text": "build and run the docker image:",
          "source_url": "https://github.com/pathwaycom/pathway#L206",
          "evidence": "You can then build and run the Docker image:"
        },
        {
          "text": "run the docker image:",
          "source_url": "https://github.com/pathwaycom/pathway#L206",
          "evidence": "You can then build and run the Docker image:"
        },
        {
          "text": "build -t my-pathway-app",
          "source_url": "https://github.com/pathwaycom/pathway#L209",
          "evidence": "docker build -t my-pathway-app ."
        },
        {
          "text": "run -it --rm --name my-pathway-app my-pathway-app",
          "source_url": "https://github.com/pathwaycom/pathway#L210",
          "evidence": "docker run -it --rm --name my-pathway-app my-pathway-app"
        },
        {
          "text": "run a single python script",
          "source_url": "https://github.com/pathwaycom/pathway#L213",
          "evidence": "#### Run a single Python script"
        },
        {
          "text": "run -it --rm --name my-pathway-app -v \"$pwd\":/app pathwaycom/pathway:latest python my-pathway-app",
          "source_url": "https://github.com/pathwaycom/pathway#L220",
          "evidence": "docker run -it --rm --name my-pathway-app -v \"$PWD\":/app pathwaycom/pathway:latest python my-pathway-app.py"
        },
        {
          "text": "run pip install -u pathway",
          "source_url": "https://github.com/pathwaycom/pathway#L230",
          "evidence": "RUN pip install -U pathway"
        },
        {
          "text": "processing and real time intelligent analytics",
          "source_url": "https://github.com/pathwaycom/pathway#L240",
          "evidence": "Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics."
        },
        {
          "text": "supports distributed kubernetes deployment, with external persistence setup",
          "source_url": "https://github.com/pathwaycom/pathway#L241",
          "evidence": "It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup."
        },
        {
          "text": "implement a lot of algorithms/udf's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines)",
          "source_url": "https://github.com/pathwaycom/pathway#L249",
          "evidence": "Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines)."
        },
        {
          "text": "processing tasks, including: flink, spark, and kafka streaming",
          "source_url": "https://github.com/pathwaycom/pathway#L249",
          "evidence": "Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines)."
        },
        {
          "text": "processing pipelines and co-promote solutions that push the boundaries of what's possible with python and streaming data",
          "source_url": "https://github.com/pathwaycom/pathway#L265",
          "evidence": "We build cutting-edge data processing pipelines and co-promote solutions that push the boundaries of what's possible with Python and streaming data."
        },
        {
          "text": "build cutting-edge data processing pipelines and co-promote solutions that push the boundaries of what's possible with python and streaming data",
          "source_url": "https://github.com/pathwaycom/pathway#L265",
          "evidence": "We build cutting-edge data processing pipelines and co-promote solutions that push the boundaries of what's possible with Python and streaming data."
        },
        {
          "text": "building context-aware ai agents",
          "source_url": "https://github.com/pathwaycom/pathway#L274",
          "evidence": "| [LlamaIndex](https://developers.llamaindex.ai/python/examples/retrievers/pathway_retriever/) | The developer-trusted framework for building context-aware AI agents. |"
        },
        {
          "text": "offering end-to-end solutions from text extraction to intelligent document understanding",
          "source_url": "https://github.com/pathwaycom/pathway#L276",
          "evidence": "| [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) | PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding. |"
        },
        {
          "text": "allows for unlimited non-commercial use, as well as use of the pathway package [for most commercial purposes](https://pathway",
          "source_url": "https://github.com/pathwaycom/pathway#L283",
          "evidence": "Pathway is distributed on a [BSL 1.1 License](https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt) which allows for unlimited non-commercial use, as well as use of the Pathway package [for most commercial purposes](https://pathway.com/license/), free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some [public repos](https://github.com/pathwaycom) which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license."
        },
        {
          "text": "integrate with this repo, we suggest releasing it first as a separate repo on a mit/apache 2",
          "source_url": "https://github.com/pathwaycom/pathway#L288",
          "evidence": "If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license."
        },
        {
          "text": "A wide range of connectors: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.",
          "source_url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        },
        {
          "text": "Stateless and stateful transformations: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.",
          "source_url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "text": "Persistence: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!",
          "source_url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        },
        {
          "text": "Consistency: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency.",
          "source_url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "text": "Scalable Rust engine: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.",
          "source_url": "https://github.com/pathwaycom/pathway#L97",
          "evidence": "- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations."
        },
        {
          "text": "LLM helpers: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.",
          "source_url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "apache/streampark",
      "url": "https://github.com/apache/streampark",
      "stars": 4217,
      "language": "Java",
      "features": [
        {
          "text": "provides a development framework for developing stream processing applications using apache flink and apache spark, alongside a professional management platform",
          "source_url": "https://github.com/apache/streampark#L32",
          "evidence": "**StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025."
        },
        {
          "text": "processing applications using apache flink and apache spark, alongside a professional management platform",
          "source_url": "https://github.com/apache/streampark#L32",
          "evidence": "**StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025."
        },
        {
          "text": "provides a streaming-application framework to accelerate apache flink and spark development, offering prebuilt plug-and-play apis and connectors",
          "source_url": "https://github.com/apache/streampark#L35",
          "evidence": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors."
        },
        {
          "text": "offering prebuilt plug-and-play apis and connectors",
          "source_url": "https://github.com/apache/streampark#L35",
          "evidence": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors."
        },
        {
          "text": "provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more",
          "source_url": "https://github.com/apache/streampark#L37",
          "evidence": "* Provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more."
        },
        {
          "text": "supports batch & streaming**",
          "source_url": "https://github.com/apache/streampark#L38",
          "evidence": "* **Supports Batch & Streaming**"
        },
        {
          "text": "supports apache flink and apache spark, enabling both stream processing and batch processing",
          "source_url": "https://github.com/apache/streampark#L39",
          "evidence": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing."
        },
        {
          "text": "processing and batch processing",
          "source_url": "https://github.com/apache/streampark#L39",
          "evidence": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing."
        },
        {
          "text": "supports multi-engine/multi-version**",
          "source_url": "https://github.com/apache/streampark#L40",
          "evidence": "* **Supports Multi-engine/Multi-version**"
        },
        {
          "text": "enables cross-version development and management of apache flink and apache spark applications within a unified framework",
          "source_url": "https://github.com/apache/streampark#L41",
          "evidence": "* Enables cross-version development and management of Apache Flink and Apache Spark applications within a unified framework."
        },
        {
          "text": "allowing even beginners to get started within minutes",
          "source_url": "https://github.com/apache/streampark#L47",
          "evidence": "* Only one service, deployment easy, allowing even beginners to get started within minutes."
        },
        {
          "text": "run -d -p 10000:10000 apache/streampark:latest",
          "source_url": "https://github.com/apache/streampark#L56",
          "evidence": "docker run -d -p 10000:10000 apache/streampark:latest"
        },
        {
          "text": "support services for this project",
          "source_url": "https://github.com/apache/streampark#L99",
          "evidence": "> If you're new to posting issues, we ask that you read [*How To Ask Questions The Smart Way*](http://www.catb.org/~esr/faqs/smart-questions.html) (**This guide does not provide actual support services for this project!**), [How to Report Bugs Effectively](http://www.chiark.greenend.org.uk/~sgtatham/bugs.html) prior to posting. Well written bug reports help us help you!"
        },
        {
          "text": "provide actual support services for this project",
          "source_url": "https://github.com/apache/streampark#L99",
          "evidence": "> If you're new to posting issues, we ask that you read [*How To Ask Questions The Smart Way*](http://www.catb.org/~esr/faqs/smart-questions.html) (**This guide does not provide actual support services for this project!**), [How to Report Bugs Effectively](http://www.chiark.greenend.org.uk/~sgtatham/bugs.html) prior to posting. Well written bug reports help us help you!"
        },
        {
          "text": "*StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025.",
          "source_url": "https://github.com/apache/streampark#L32",
          "evidence": "**StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025."
        },
        {
          "text": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors.",
          "source_url": "https://github.com/apache/streampark#L35",
          "evidence": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors."
        },
        {
          "text": "* Provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more.",
          "source_url": "https://github.com/apache/streampark#L37",
          "evidence": "* Provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more."
        },
        {
          "text": "Supports Batch & Streaming",
          "source_url": "https://github.com/apache/streampark#L38",
          "evidence": "* **Supports Batch & Streaming**"
        },
        {
          "text": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing.",
          "source_url": "https://github.com/apache/streampark#L39",
          "evidence": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing."
        },
        {
          "text": "Supports Multi-engine/Multi-version",
          "source_url": "https://github.com/apache/streampark#L40",
          "evidence": "* **Supports Multi-engine/Multi-version**"
        },
        {
          "text": "* Enables cross-version development and management of Apache Flink and Apache Spark applications within a unified framework.",
          "source_url": "https://github.com/apache/streampark#L41",
          "evidence": "* Enables cross-version development and management of Apache Flink and Apache Spark applications within a unified framework."
        },
        {
          "text": "* Only one service, deployment easy, allowing even beginners to get started within minutes.",
          "source_url": "https://github.com/apache/streampark#L47",
          "evidence": "* Only one service, deployment easy, allowing even beginners to get started within minutes."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "lakehq/sail",
      "url": "https://github.com/lakehq/sail",
      "stars": 1020,
      "language": "Rust",
      "features": [
        {
          "text": "build status](https://github",
          "source_url": "https://github.com/lakehq/sail#L3",
          "evidence": "[![Build Status](https://github.com/lakehq/sail/actions/workflows/build.yml/badge.svg?branch=main&event=push)](https://github.com/lakehq/sail/actions)"
        },
        {
          "text": "supporting the spark sql and dataframe api with no code rewrites required",
          "source_url": "https://github.com/lakehq/sail#L12",
          "evidence": "- **Compatible** with the Spark Connect protocol, supporting the Spark SQL and DataFrame API with no code rewrites required."
        },
        {
          "text": "process step-by-step",
          "source_url": "https://github.com/lakehq/sail#L39",
          "evidence": "You can install Sail from source to optimize performance for your specific hardware architecture. The detailed [Installation Guide](https://docs.lakesail.com/sail/latest/introduction/installation/) walks you through this process step-by-step."
        },
        {
          "text": "provides comprehensive instructions for deploying sail on kubernetes clusters and other infrastructure configurations",
          "source_url": "https://github.com/lakehq/sail#L41",
          "evidence": "If you need to deploy Sail in production environments, the [Deployment Guide](https://docs.lakesail.com/sail/latest/guide/deployment/) provides comprehensive instructions for deploying Sail on Kubernetes clusters and other infrastructure configurations."
        },
        {
          "text": "import sparkconnectserver",
          "source_url": "https://github.com/lakehq/sail#L56",
          "evidence": "from pysail.spark import SparkConnectServer"
        },
        {
          "text": "run sail in cluster mode for distributed processing",
          "source_url": "https://github.com/lakehq/sail#L62",
          "evidence": "**Option 3: Kubernetes.** You can deploy Sail on Kubernetes and run Sail in cluster mode for distributed processing."
        },
        {
          "text": "building the docker image and writing the kubernetes manifest yaml file",
          "source_url": "https://github.com/lakehq/sail#L63",
          "evidence": "Please refer to the [Kubernetes Deployment Guide](https://docs.lakesail.com/sail/latest/guide/deployment/kubernetes.html) for instructions on building the Docker image and writing the Kubernetes manifest YAML file."
        },
        {
          "text": "import sparksession",
          "source_url": "https://github.com/lakehq/sail#L76",
          "evidence": "from pyspark.sql import SparkSession"
        },
        {
          "text": "supports a variety of storage backends for reading and writing data",
          "source_url": "https://github.com/lakehq/sail#L88",
          "evidence": "Sail supports a variety of storage backends for reading and writing data. You can read more details in our [Storage Guide](https://docs.lakesail.com/sail/latest/guide/storage/)."
        },
        {
          "text": "support for delta lake, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing delta datasets",
          "source_url": "https://github.com/lakehq/sail#L104",
          "evidence": "Sail provides native support for **Delta Lake**, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing Delta datasets."
        },
        {
          "text": "provides native support for delta lake, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing delta datasets",
          "source_url": "https://github.com/lakehq/sail#L104",
          "evidence": "Sail provides native support for **Delta Lake**, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing Delta datasets."
        },
        {
          "text": "offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing delta datasets",
          "source_url": "https://github.com/lakehq/sail#L104",
          "evidence": "Sail provides native support for **Delta Lake**, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing Delta datasets."
        },
        {
          "text": "create a [pull request](https://github",
          "source_url": "https://github.com/lakehq/sail#L135",
          "evidence": "Feel free to create a [pull request](https://github.com/lakehq/sail/pulls) if you would like to make a code change."
        },
        {
          "text": "processing and powered etl, machine learning, and analytics pipelines across industries",
          "source_url": "https://github.com/lakehq/sail#L142",
          "evidence": "When Spark was invented over 15 years ago, it was revolutionary. It redefined distributed data processing and powered ETL, machine learning, and analytics pipelines across industries."
        },
        {
          "text": "performs poorly on analytical workloads and leaves hardware efficiency untapped",
          "source_url": "https://github.com/lakehq/sail#L149",
          "evidence": "- **Row-based processing** performs poorly on analytical workloads and leaves hardware efficiency untapped."
        },
        {
          "text": "offers a drop-in replacement for spark sql and the spark dataframe api",
          "source_url": "https://github.com/lakehq/sail#L156",
          "evidence": "Sail offers a drop-in replacement for Spark SQL and the Spark DataFrame API. Existing PySpark code works out of the box once you connect the Spark session to Sail over the Spark Connect protocol."
        },
        {
          "text": "run on sail with identical semantics",
          "source_url": "https://github.com/lakehq/sail#L159",
          "evidence": "- **DataFrame API Support.** Spark DataFrame operations run on Sail with identical semantics."
        },
        {
          "text": "enable zero-copy data sharing",
          "source_url": "https://github.com/lakehq/sail#L166",
          "evidence": "- **Lightning-Fast Python UDFs.** Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing."
        },
        {
          "text": "runs inside sail with zero serialization overhead as arrow array pointers enable zero-copy data sharing",
          "source_url": "https://github.com/lakehq/sail#L166",
          "evidence": "- **Lightning-Fast Python UDFs.** Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing."
        },
        {
          "text": "handles execution for local and cluster modes",
          "source_url": "https://github.com/lakehq/sail#L176",
          "evidence": "- [Query Planning](https://docs.lakesail.com/sail/latest/concepts/query-planning/) \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes."
        },
        {
          "text": "builds logical and physical plans, and handles execution for local and cluster modes",
          "source_url": "https://github.com/lakehq/sail#L176",
          "evidence": "- [Query Planning](https://docs.lakesail.com/sail/latest/concepts/query-planning/) \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes."
        },
        {
          "text": "Compatible with the Spark Connect protocol, supporting the Spark SQL and DataFrame API with no code rewrites required.",
          "source_url": "https://github.com/lakehq/sail#L12",
          "evidence": "- **Compatible** with the Spark Connect protocol, supporting the Spark SQL and DataFrame API with no code rewrites required."
        },
        {
          "text": "100% Rust-native with no JVM overhead, delivering memory safety, instant startup, and predictable performance.",
          "source_url": "https://github.com/lakehq/sail#L15",
          "evidence": "- **100% Rust-native** with no JVM overhead, delivering memory safety, instant startup, and predictable performance."
        },
        {
          "text": "*Option 3: Kubernetes.** You can deploy Sail on Kubernetes and run Sail in cluster mode for distributed processing.",
          "source_url": "https://github.com/lakehq/sail#L62",
          "evidence": "**Option 3: Kubernetes.** You can deploy Sail on Kubernetes and run Sail in cluster mode for distributed processing."
        },
        {
          "text": "Row-based processing performs poorly on analytical workloads and leaves hardware efficiency untapped.",
          "source_url": "https://github.com/lakehq/sail#L149",
          "evidence": "- **Row-based processing** performs poorly on analytical workloads and leaves hardware efficiency untapped."
        },
        {
          "text": "Spark SQL Dialect Support. A custom Rust parser (built with parser combinators and Rust procedural macros) covers Spark SQL syntax with production-grade accuracy.",
          "source_url": "https://github.com/lakehq/sail#L158",
          "evidence": "- **Spark SQL Dialect Support.** A custom Rust parser (built with parser combinators and Rust procedural macros) covers Spark SQL syntax with production-grade accuracy."
        },
        {
          "text": "DataFrame API Support. Spark DataFrame operations run on Sail with identical semantics.",
          "source_url": "https://github.com/lakehq/sail#L159",
          "evidence": "- **DataFrame API Support.** Spark DataFrame operations run on Sail with identical semantics."
        },
        {
          "text": "Python UDF, UDAF, UDWF, and UDTF Support. Python, Pandas, and Arrow UDFs all follow the same conventions as Spark.",
          "source_url": "https://github.com/lakehq/sail#L160",
          "evidence": "- **Python UDF, UDAF, UDWF, and UDTF Support.** Python, Pandas, and Arrow UDFs all follow the same conventions as Spark."
        },
        {
          "text": "Lightning-Fast Python UDFs. Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing.",
          "source_url": "https://github.com/lakehq/sail#L166",
          "evidence": "- **Lightning-Fast Python UDFs.** Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing."
        },
        {
          "text": "Performant Data Shuffling. Workers exchange Arrow columnar data directly, minimizing shuffle costs for joins and aggregations.",
          "source_url": "https://github.com/lakehq/sail#L167",
          "evidence": "- **Performant Data Shuffling.** Workers exchange Arrow columnar data directly, minimizing shuffle costs for joins and aggregations."
        },
        {
          "text": "Query Planning \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes.",
          "source_url": "https://github.com/lakehq/sail#L176",
          "evidence": "- [Query Planning](https://docs.lakesail.com/sail/latest/concepts/query-planning/) \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "BabitMF/bmf",
      "url": "https://github.com/BabitMF/bmf",
      "stars": 981,
      "language": "C++",
      "features": [
        {
          "text": "processing framework with strong gpu acceleration",
          "source_url": "https://github.com/BabitMF/bmf#L1",
          "evidence": "# BMF - Cross-platform, multi-language, customizable video processing framework with strong GPU acceleration"
        },
        {
          "text": "processing framework developed by [bytedance](https://www",
          "source_url": "https://github.com/BabitMF/bmf#L3",
          "evidence": "**BMF (Babit Multimedia Framework)** is a cross-platform, multi-language, customizable multimedia processing framework developed by [**ByteDance**](https://www.bytedance.com/en)."
        },
        {
          "text": "processing scenarios",
          "source_url": "https://github.com/BabitMF/bmf#L4",
          "evidence": "With over 4 years of testing and improvements, BMF has been tailored to adeptly tackle challenges in our real-world production environments. It is currently widely used in ByteDance's video streaming, live transcoding, cloud editing and mobile pre/post processing scenarios. More than 2 billion videos are processed by the framework every day."
        },
        {
          "text": "provides python, go, and c++ apis, allowing developers the flexibility to code in their favourite languages",
          "source_url": "https://github.com/BabitMF/bmf#L10",
          "evidence": "- **Easy to use:** BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages."
        },
        {
          "text": "allowing developers the flexibility to code in their favourite languages",
          "source_url": "https://github.com/BabitMF/bmf#L10",
          "evidence": "- **Easy to use:** BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages."
        },
        {
          "text": "support for heterogeneous acceleration hardware",
          "source_url": "https://github.com/BabitMF/bmf#L14",
          "evidence": "- **High performance:** BMF has a powerful scheduler and strong support for heterogeneous acceleration hardware. Moreover, [**NVIDIA**](https://www.nvidia.com/) has been cooperating with us to develop a highly optimized GPU pipeline for video transcoding and AI inference."
        },
        {
          "text": "offers seamless data format conversions across popular frameworks (ffmpeg/numpy/pytorch/opencv/tensorrt), conversion between hardware devices (cpu/gpu), and color space and pixel format conversion",
          "source_url": "https://github.com/BabitMF/bmf#L16",
          "evidence": "- **Efficient data conversion:** BMF offers seamless data format conversions across popular frameworks (FFmpeg/Numpy/PyTorch/OpenCV/TensorRT), conversion between hardware devices (CPU/GPU), and color space and pixel format conversion."
        },
        {
          "text": "processing framework",
          "source_url": "https://github.com/BabitMF/bmf#L19",
          "evidence": "[**BMFLite**](./bmf_lite/README.md) is a client-side cross-platform, lightweight, more efficient client-side multimedia processing framework."
        },
        {
          "text": "processing videos and pictures trillions of times every day",
          "source_url": "https://github.com/BabitMF/bmf#L20",
          "evidence": "So far, the BMFLite client-side algorithm is used in apps such as Douyin/Xigua, serving more than one billion users in live streaming/video playing/pictures/cloud games and other scenarios, and processing videos and pictures trillions of times every day."
        },
        {
          "text": "allowing you to experience them intuitively",
          "source_url": "https://github.com/BabitMF/bmf#L25",
          "evidence": "In this section, we will directly showcase the capabilities of the BMF framework around six dimensions: **Transcode**, **Edit**, **Meeting/Broadcaster**, **GPU acceleration**, **AI Inference**, and **client-side Framework**. For all the demos provided below, corresponding implementations and documentation are available on Google Colab, allowing you to experience them intuitively."
        },
        {
          "text": "implement a high-complexity audio and video editing pipeline through the bmf framework",
          "source_url": "https://github.com/BabitMF/bmf#L33",
          "evidence": "The Edit Demo will show you how to implement a high-complexity audio and video editing pipeline through the BMF framework. We have implemented two Python modules, video_concat and video_overlay, and combined various atomic capabilities to construct a complex BMF Graph."
        },
        {
          "text": "enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an rtmp server",
          "source_url": "https://github.com/BabitMF/bmf#L38",
          "evidence": "This demo uses BMF framework to construct a simple broadcast service. The service provides an API that enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an RTMP server. This demo showcases the modularity of BMF, multi-language development, and the ability to dynamically adjust the pipeline."
        },
        {
          "text": "provides an api that enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an rtmp server",
          "source_url": "https://github.com/BabitMF/bmf#L38",
          "evidence": "This demo uses BMF framework to construct a simple broadcast service. The service provides an API that enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an RTMP server. This demo showcases the modularity of BMF, multi-language development, and the ability to dynamically adjust the pipeline."
        },
        {
          "text": "extend easily, there are new c++, python modules added simply",
          "source_url": "https://github.com/BabitMF/bmf#L52",
          "evidence": "*   Ability to extend easily, there are new C++, Python modules added simply"
        },
        {
          "text": "process between cpu and gpu",
          "source_url": "https://github.com/BabitMF/bmf#L57",
          "evidence": "*   Heterogeneous pipeline is supported in BMF, such as process between CPU and GPU"
        },
        {
          "text": "builds a transcoding pipeline which fully runs on gpu:",
          "source_url": "https://github.com/BabitMF/bmf#L68",
          "evidence": "The demo builds a transcoding pipeline which fully runs on GPU:"
        },
        {
          "text": "processing each day",
          "source_url": "https://github.com/BabitMF/bmf#L79",
          "evidence": "The [prototype]() of how to build a video preprocessing for LLM training data in Bytedance, which serves billions of clip processing each day."
        },
        {
          "text": "build a video preprocessing for llm training data in bytedance, which serves billions of clip processing each day",
          "source_url": "https://github.com/BabitMF/bmf#L79",
          "evidence": "The [prototype]() of how to build a video preprocessing for LLM training data in Bytedance, which serves billions of clip processing each day."
        },
        {
          "text": "integrate the state of art ai algorithms into the bmf video processing pipeline",
          "source_url": "https://github.com/BabitMF/bmf#L88",
          "evidence": "This demo shows how to integrate the state of art AI algorithms into the BMF video processing pipeline. The famous open source colorization algorithm [DeOldify](https://github.com/jantic/DeOldify) is wrapped as a BMF pyhton module in less than 100 lines of codes. The final effect is illustrated below, with the original video on the left side and the colored video on the right."
        },
        {
          "text": "processing pipeline",
          "source_url": "https://github.com/BabitMF/bmf#L88",
          "evidence": "This demo shows how to integrate the state of art AI algorithms into the BMF video processing pipeline. The famous open source colorization algorithm [DeOldify](https://github.com/jantic/DeOldify) is wrapped as a BMF pyhton module in less than 100 lines of codes. The final effect is illustrated below, with the original video on the left side and the colored video on the right."
        },
        {
          "text": "implements the super-resolution inference process of [real-esrgan](https://github",
          "source_url": "https://github.com/BabitMF/bmf#L95",
          "evidence": "This demo implements the super-resolution inference process of [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) as a BMF module, showcasing a BMF pipeline that combines decoding, super-resolution inference and encoding."
        },
        {
          "text": "process of [real-esrgan](https://github",
          "source_url": "https://github.com/BabitMF/bmf#L95",
          "evidence": "This demo implements the super-resolution inference process of [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) as a BMF module, showcasing a BMF pipeline that combines decoding, super-resolution inference and encoding."
        },
        {
          "text": "process the input video",
          "source_url": "https://github.com/BabitMF/bmf#L108",
          "evidence": "This Demo shows a full-link face detect pipeline based on TensorRT acceleration, which internally uses the TensorRT-accelerated Onnx model to process the input video. It uses the NMS algorithm to filter repeated candidate boxes to form an output, which can be used to process a Face Detection Task efficiently."
        },
        {
          "text": "process a face detection task efficiently",
          "source_url": "https://github.com/BabitMF/bmf#L108",
          "evidence": "This Demo shows a full-link face detect pipeline based on TensorRT acceleration, which internally uses the TensorRT-accelerated Onnx model to process the input video. It uses the NMS algorithm to filter repeated candidate boxes to form an output, which can be used to process a Face Detection Task efficiently."
        },
        {
          "text": "implements the denoise algorithm as a bmf module, showcasing a bmf pipeline that combines video capture, noise reduction and rendering",
          "source_url": "https://github.com/BabitMF/bmf#L120",
          "evidence": "This example implements the denoise algorithm as a BMF module, showcasing a BMF pipeline that combines video capture, noise reduction and rendering."
        },
        {
          "text": "create a graph](https://babitmf",
          "source_url": "https://github.com/BabitMF/bmf#L143",
          "evidence": "- [Create a Graph](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_graph/)"
        },
        {
          "text": "create a module](https://babitmf",
          "source_url": "https://github.com/BabitMF/bmf#L151",
          "evidence": "- [Create a Module](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_module/)"
        },
        {
          "text": "customize module with python, c++ and go",
          "source_url": "https://github.com/BabitMF/bmf#L152",
          "evidence": "- customize module with python, C++ and Go. You can try it on [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BabitMF/bmf/blob/master/bmf/test/customize_module/bmf_customize_demo_latest.ipynb)"
        },
        {
          "text": "track and resolve problems",
          "source_url": "https://github.com/BabitMF/bmf#L186",
          "evidence": "We use GitHub issues to track and resolve problems. If you have any questions, please feel free to join the discussion and work with us to find a solution."
        },
        {
          "text": "*BMF (Babit Multimedia Framework) is a cross-platform, multi-language, customizable multimedia processing framework developed by ByteDance**.",
          "source_url": "https://github.com/BabitMF/bmf#L3",
          "evidence": "**BMF (Babit Multimedia Framework)** is a cross-platform, multi-language, customizable multimedia processing framework developed by [**ByteDance**](https://www.bytedance.com/en)."
        },
        {
          "text": "Cross-Platform Support: Native compatibility with Linux, Windows, and macOS, as well as optimization for both x86 and ARM CPUs.",
          "source_url": "https://github.com/BabitMF/bmf#L8",
          "evidence": "- **Cross-Platform Support:** Native compatibility with Linux, Windows, and macOS, as well as optimization for both x86 and ARM CPUs."
        },
        {
          "text": "Easy to use: BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages.",
          "source_url": "https://github.com/BabitMF/bmf#L10",
          "evidence": "- **Easy to use:** BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages."
        },
        {
          "text": "High performance: BMF has a powerful scheduler and strong support for heterogeneous acceleration hardware. Moreover, NVIDIA has been cooperating with us to develop a highly optimized GPU pipeline for video transcoding and AI inference.",
          "source_url": "https://github.com/BabitMF/bmf#L14",
          "evidence": "- **High performance:** BMF has a powerful scheduler and strong support for heterogeneous acceleration hardware. Moreover, [**NVIDIA**](https://www.nvidia.com/) has been cooperating with us to develop a highly optimized GPU pipeline for video transcoding and AI inference."
        },
        {
          "text": "Efficient data conversion: BMF offers seamless data format conversions across popular frameworks (FFmpeg/Numpy/PyTorch/OpenCV/TensorRT), conversion between hardware devices (CPU/GPU), and color space and pixel format conversion.",
          "source_url": "https://github.com/BabitMF/bmf#L16",
          "evidence": "- **Efficient data conversion:** BMF offers seamless data format conversions across popular frameworks (FFmpeg/Numpy/PyTorch/OpenCV/TensorRT), conversion between hardware devices (CPU/GPU), and color space and pixel format conversion."
        },
        {
          "text": "*   Ability to extend easily, there are new C++, Python modules added simply",
          "source_url": "https://github.com/BabitMF/bmf#L52",
          "evidence": "*   Ability to extend easily, there are new C++, Python modules added simply"
        },
        {
          "text": "*   Heterogeneous pipeline is supported in BMF, such as process between CPU and GPU",
          "source_url": "https://github.com/BabitMF/bmf#L57",
          "evidence": "*   Heterogeneous pipeline is supported in BMF, such as process between CPU and GPU"
        },
        {
          "text": "- Create a Graph",
          "source_url": "https://github.com/BabitMF/bmf#L143",
          "evidence": "- [Create a Graph](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_graph/)"
        },
        {
          "text": "- Create a Module",
          "source_url": "https://github.com/BabitMF/bmf#L151",
          "evidence": "- [Create a Module](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_module/)"
        },
        {
          "text": "- customize module with python, C++ and Go. You can try it on ![Open In Colab](https://colab.research.google.com/github/BabitMF/bmf/blob/master/bmf/test/customize_module/bmf_customize_demo_latest.ipynb)",
          "source_url": "https://github.com/BabitMF/bmf#L152",
          "evidence": "- customize module with python, C++ and Go. You can try it on [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BabitMF/bmf/blob/master/bmf/test/customize_module/bmf_customize_demo_latest.ipynb)"
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "digitalocean/firebolt",
      "url": "https://github.com/digitalocean/firebolt",
      "stars": 713,
      "language": "Go",
      "features": [
        {
          "text": "build status](https://github",
          "source_url": "https://github.com/digitalocean/firebolt#L1",
          "evidence": "# firebolt ![Code Coverage Badge by Gopherbadger](coverage_badge.png)  ![Build Status](https://github.com/digitalocean/firebolt/actions/workflows/ci.yml/badge.svg) [![Go Report Card](https://goreportcard.com/badge/digitalocean/firebolt)](https://goreportcard.com/report/digitalocean/firebolt)"
        },
        {
          "text": "processing & data pipeline apps",
          "source_url": "https://github.com/digitalocean/firebolt#L4",
          "evidence": "A golang framework for streaming event processing & data pipeline apps"
        },
        {
          "text": "process a stream of data",
          "source_url": "https://github.com/digitalocean/firebolt#L7",
          "evidence": "Firebolt has a simple model intended to make it easier to write reliable pipeline applications that process a stream of data."
        },
        {
          "text": "build systems such as:",
          "source_url": "https://github.com/digitalocean/firebolt#L9",
          "evidence": "It can be used to build systems such as:"
        },
        {
          "text": "processing pipelines",
          "source_url": "https://github.com/digitalocean/firebolt#L12",
          "evidence": "* event processing pipelines"
        },
        {
          "text": "implement the `node",
          "source_url": "https://github.com/digitalocean/firebolt#L15",
          "evidence": "must implement the `node.Source` interface."
        },
        {
          "text": "provide one built-in source:",
          "source_url": "https://github.com/digitalocean/firebolt#L17",
          "evidence": "We provide one built-in source:"
        },
        {
          "text": "processing of your application is executed by its nodes which form a processing tree",
          "source_url": "https://github.com/digitalocean/firebolt#L21",
          "evidence": "The processing of your application is executed by its **nodes** which form a processing tree.  Data - events - flow down"
        },
        {
          "text": "process events synchronously or",
          "source_url": "https://github.com/digitalocean/firebolt#L22",
          "evidence": "this tree.   A parent **node** passes results down to it's child **nodes**.  Nodes may process events synchronously or"
        },
        {
          "text": "implement the `node",
          "source_url": "https://github.com/digitalocean/firebolt#L24",
          "evidence": "cases.  Each node must implement the `node.SyncNode`, `node.FanoutNode`, or `node.AsyncNode` interfaces accordingly."
        },
        {
          "text": "provide two built-in node types:",
          "source_url": "https://github.com/digitalocean/firebolt#L26",
          "evidence": "We provide two built-in node types:"
        },
        {
          "text": "run and compile-time dependencies on `librdkafka`, see developing",
          "source_url": "https://github.com/digitalocean/firebolt#L31",
          "evidence": "Firebolt has both run and compile-time dependencies on `librdkafka`, see [Developing](#developing)"
        },
        {
          "text": "handle large data volume",
          "source_url": "https://github.com/digitalocean/firebolt#L45",
          "evidence": "to run a clustered application that scales predictably to handle large data volume."
        },
        {
          "text": "run a clustered application that scales predictably to handle large data volume",
          "source_url": "https://github.com/digitalocean/firebolt#L45",
          "evidence": "to run a clustered application that scales predictably to handle large data volume."
        },
        {
          "text": "support 'wide operations' like record grouping, windowing,",
          "source_url": "https://github.com/digitalocean/firebolt#L47",
          "evidence": "It is not an analytics tool - it does not provide an easy way to support 'wide operations' like record grouping, windowing,"
        },
        {
          "text": "provide an easy way to support 'wide operations' like record grouping, windowing,",
          "source_url": "https://github.com/digitalocean/firebolt#L47",
          "evidence": "It is not an analytics tool - it does not provide an easy way to support 'wide operations' like record grouping, windowing,"
        },
        {
          "text": "processing pipelines that are",
          "source_url": "https://github.com/digitalocean/firebolt#L48",
          "evidence": "or sorting that require shuffling data within the cluster.   Firebolt is for 'straight through' processing pipelines that are"
        },
        {
          "text": "processing to a kafka topic for recovery or analysis with a few lines of config",
          "source_url": "https://github.com/digitalocean/firebolt#L56",
          "evidence": "* **convenient error handling** Send events that fail processing to a kafka topic for recovery or analysis with a few lines of config"
        },
        {
          "text": "process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window",
          "source_url": "https://github.com/digitalocean/firebolt#L58",
          "evidence": "* **outage recovery: parallel recovery** After an outage, process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window."
        },
        {
          "text": "track the performance of your source and all nodes without writing code",
          "source_url": "https://github.com/digitalocean/firebolt#L59",
          "evidence": "* **monitorability** Firebolt exposes Prometheus metrics to track the performance of your Source and all Nodes without writing code.  Your nodes can expose their own custom internal metrics as needed."
        },
        {
          "text": "processing that may need to be conducted on one-and-only-one instance",
          "source_url": "https://github.com/digitalocean/firebolt#L60",
          "evidence": "* **leader election** Firebolt uses Zookeeper to conduct leader elections, facilitating any processing that may need to be conducted on one-and-only-one instance."
        },
        {
          "text": "implementing and using sources",
          "source_url": "https://github.com/digitalocean/firebolt#L73",
          "evidence": "5. [Sources ](docs/sources.md) Implementing and using sources"
        },
        {
          "text": "implementing and using synchronous nodes",
          "source_url": "https://github.com/digitalocean/firebolt#L75",
          "evidence": "6. [Sync Nodes ](docs/sync-nodes.md) Implementing and using synchronous nodes"
        },
        {
          "text": "implementing and using fanout nodes",
          "source_url": "https://github.com/digitalocean/firebolt#L77",
          "evidence": "7. [Fanout Nodes ](docs/fanout-nodes.md) Implementing and using fanout nodes"
        },
        {
          "text": "implementing and using asynchronous nodes",
          "source_url": "https://github.com/digitalocean/firebolt#L79",
          "evidence": "8. [Async Nodes ](docs/async-nodes.md) Implementing and using asynchronous nodes"
        },
        {
          "text": "event processing pipelines",
          "source_url": "https://github.com/digitalocean/firebolt#L12",
          "evidence": "* event processing pipelines"
        },
        {
          "text": "* kafka sources Minimal configuration and no code required to consume from a Kafka topic, consumer lag metrics included",
          "source_url": "https://github.com/digitalocean/firebolt#L52",
          "evidence": "* **kafka sources** Minimal configuration and no code required to consume from a Kafka topic, consumer lag metrics included"
        },
        {
          "text": "* convenient error handling Send events that fail processing to a kafka topic for recovery or analysis with a few lines of config",
          "source_url": "https://github.com/digitalocean/firebolt#L56",
          "evidence": "* **convenient error handling** Send events that fail processing to a kafka topic for recovery or analysis with a few lines of config"
        },
        {
          "text": "* outage recovery: offset management Configurable Kafka offset management during recovery lets you determine the maximum \"catch up\" to attempt after an outage, so you can quickly get back to realtime processing.",
          "source_url": "https://github.com/digitalocean/firebolt#L57",
          "evidence": "* **outage recovery: offset management** Configurable Kafka offset management during recovery lets you determine the maximum \"catch up\" to attempt after an outage, so you can quickly get back to realtime processing."
        },
        {
          "text": "* outage recovery: parallel recovery After an outage, process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window.",
          "source_url": "https://github.com/digitalocean/firebolt#L58",
          "evidence": "* **outage recovery: parallel recovery** After an outage, process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window."
        },
        {
          "text": "* monitorability Firebolt exposes Prometheus metrics to track the performance of your Source and all Nodes without writing code.  Your nodes can expose their own custom internal metrics as needed.",
          "source_url": "https://github.com/digitalocean/firebolt#L59",
          "evidence": "* **monitorability** Firebolt exposes Prometheus metrics to track the performance of your Source and all Nodes without writing code.  Your nodes can expose their own custom internal metrics as needed."
        },
        {
          "text": "* leader election Firebolt uses Zookeeper to conduct leader elections, facilitating any processing that may need to be conducted on one-and-only-one instance.",
          "source_url": "https://github.com/digitalocean/firebolt#L60",
          "evidence": "* **leader election** Firebolt uses Zookeeper to conduct leader elections, facilitating any processing that may need to be conducted on one-and-only-one instance."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "LegacyLands/legacy-lands-library",
      "url": "https://github.com/LegacyLands/legacy-lands-library",
      "stars": 706,
      "language": "Java",
      "features": [
        {
          "text": "runs as a plugin, aiming to encapsulate various existing libraries to simplify the development of plugins",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L10",
          "evidence": "<p>Based on <a href=\"https://github.com/FairyProject/fairy\" target=\"_blank\">Fairy Framework</a>, it runs as a plugin, aiming to encapsulate various existing libraries to simplify the development of plugins.</p>"
        },
        {
          "text": "plugin toolkit built on [fairy framework](https://github",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L15",
          "evidence": "A Modular Plugin Toolkit built on [Fairy Framework](https://github.com/FairyProject/fairy), featuring modular design and"
        },
        {
          "text": "provides essential tools and utilities for modern minecraft plugin development with cross-platform support for",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L17",
          "evidence": "It provides essential tools and utilities for modern Minecraft plugin development with cross-platform support for"
        },
        {
          "text": "plugin development with cross-platform support for",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L17",
          "evidence": "It provides essential tools and utilities for modern Minecraft plugin development with cross-platform support for"
        },
        {
          "text": "processing framework with flexible scanning options and",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L24",
          "evidence": "- [**annotation**](annotation/README.md) - Powerful annotation processing framework with flexible scanning options and"
        },
        {
          "text": "building high-performance",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L35",
          "evidence": "- [**player**](player/README.md) - Enterprise-grade distributed data management framework building high-performance"
        },
        {
          "text": "supports `rhino`, `nashorn` and `v8` `javascript` engines",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L39",
          "evidence": "that supports `Rhino`, `Nashorn` and `V8` `JavaScript` engines."
        },
        {
          "text": "plugin decoupling and",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L44",
          "evidence": "via gRPC external task schedulers (currently implemented in Rust), enabling large plugin decoupling and"
        },
        {
          "text": "plugin development project, and will release the",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L55",
          "evidence": "In fact, we plan to extensively utilize this version in a large-scale plugin development project, and will release the"
        },
        {
          "text": "plugin for direct server use",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L63",
          "evidence": "- `-plugin`: Compiled plugin for direct server use"
        },
        {
          "text": "configure github authentication",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L70",
          "evidence": "Configure GitHub authentication"
        },
        {
          "text": "annotation - Powerful annotation processing framework with flexible scanning options and",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L24",
          "evidence": "- [**annotation**](annotation/README.md) - Powerful annotation processing framework with flexible scanning options and"
        },
        {
          "text": "commons - Essential utilities including VarHandle injection, task scheduling, virtual thread",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L28",
          "evidence": "- [**commons**](commons/README.md) - Essential utilities including VarHandle injection, task scheduling, virtual thread"
        },
        {
          "text": "player - Enterprise-grade distributed data management framework building high-performance",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L35",
          "evidence": "- [**player**](player/README.md) - Enterprise-grade distributed data management framework building high-performance"
        },
        {
          "text": "script - Powerful, flexible, extensible, and high-performance script execution engine wrapper",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L38",
          "evidence": "- [**script**](script/README.md) - Powerful, flexible, extensible, and high-performance script execution engine wrapper"
        },
        {
          "text": "experimental - Some experimental modules that can significantly improve performance, but",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L41",
          "evidence": "- [**experimental**](experimental/README.md) - Some experimental modules that can significantly improve performance, but"
        },
        {
          "text": "- third-party-schedulers - Achieves distributed task processing",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L43",
          "evidence": "- [**third-party-schedulers**](experimental/third-party-schedulers/README.md) - Achieves distributed task processing"
        },
        {
          "text": "`-javadoc`: Generated API documentation",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L62",
          "evidence": "- `-javadoc`: Generated API documentation"
        },
        {
          "text": "`-plugin`: Compiled plugin for direct server use",
          "source_url": "https://github.com/LegacyLands/legacy-lands-library#L63",
          "evidence": "- `-plugin`: Compiled plugin for direct server use"
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "rlink-rs/rlink-rs",
      "url": "https://github.com/rlink-rs/rlink-rs",
      "stars": 471,
      "language": "Rust",
      "features": [
        {
          "text": "processing framework",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L8",
          "evidence": "High performance Stream Processing Framework. A new, faster, implementation of Apache Flink from scratch in Rust."
        },
        {
          "text": "build --color=always --all --all-targets",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L79",
          "evidence": "cargo build --color=always --all --all-targets"
        },
        {
          "text": "build --release --color=always --all --all-targets",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L81",
          "evidence": "cargo build --release --color=always --all --all-targets"
        },
        {
          "text": "build image example-simple",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L212",
          "evidence": "### Build image example-simple"
        },
        {
          "text": "build -t xxx:xx -f",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L215",
          "evidence": "sudo docker build -t xxx:xx -f ./docker/Dockerfile_example_simple ."
        },
        {
          "text": "-F \"file=@/path/to/execute_file\" \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L132",
          "evidence": "-F \"file=@/path/to/execute_file\" \\"
        },
        {
          "text": "-d '{\"batch_args\":[{\"cluster_mode\":\"Standalone\", \"manager_type\":\"Coordinator\",\"num_task_managers\":\"15\"}]}' \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L139",
          "evidence": "-d '{\"batch_args\":[{\"cluster_mode\":\"Standalone\", \"manager_type\":\"Coordinator\",\"num_task_managers\":\"15\"}]}' \\"
        },
        {
          "text": "--worker_process_path hdfs://nn/path/to/rlink-showcase \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L171",
          "evidence": "--worker_process_path hdfs://nn/path/to/rlink-showcase \\"
        },
        {
          "text": "--java_manager_path hdfs://nn/path/to/rlink-yarn-manager-{version}-jar-with-dependencies.jar \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L172",
          "evidence": "--java_manager_path hdfs://nn/path/to/rlink-yarn-manager-{version}-jar-with-dependencies.jar \\"
        },
        {
          "text": "--yarn_manager_main_class rlink.yarn.manager.ResourceManagerCli \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L173",
          "evidence": "--yarn_manager_main_class rlink.yarn.manager.ResourceManagerCli \\"
        },
        {
          "text": "--manager_type Coordinator \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L181",
          "evidence": "--manager_type Coordinator \\"
        },
        {
          "text": "--num_task_managers 80 \\",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L182",
          "evidence": "--num_task_managers 80 \\"
        },
        {
          "text": "--application_process_arg xxx",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L183",
          "evidence": "--application_process_arg xxx"
        },
        {
          "text": "KubeConfig, configurable via ~/.kube/config. You can verify permissions by running kubectl auth can-i <list|create|edit|delete> pods",
          "source_url": "https://github.com/rlink-rs/rlink-rs#L191",
          "evidence": "- KubeConfig, configurable via ~/.kube/config. You can verify permissions by running kubectl auth can-i <list|create|edit|delete> pods"
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "gojek/ziggurat",
      "url": "https://github.com/gojek/ziggurat",
      "stars": 404,
      "language": "Clojure",
      "features": [
        {
          "text": "build status\" />",
          "source_url": "https://github.com/gojek/ziggurat#L9",
          "evidence": "<img src=\"https://travis-ci.com/gojek/ziggurat.svg?branch=master\" alt=\"Build Status\" />"
        },
        {
          "text": "processing on kafka",
          "source_url": "https://github.com/gojek/ziggurat#L34",
          "evidence": "Ziggurat is a framework built to simplify stream processing on Kafka. It can be used to create a full-fledged Clojure app that reads and processes messages from Kafka. Ziggurat abstracts the following features:"
        },
        {
          "text": "create a full-fledged clojure app that reads and processes messages from kafka",
          "source_url": "https://github.com/gojek/ziggurat#L34",
          "evidence": "Ziggurat is a framework built to simplify stream processing on Kafka. It can be used to create a full-fledged Clojure app that reads and processes messages from Kafka. Ziggurat abstracts the following features:"
        },
        {
          "text": "run docker-compose: `docker-compose up`",
          "source_url": "https://github.com/gojek/ziggurat#L58",
          "evidence": "3. Run docker-compose: `docker-compose up`. This starts:"
        },
        {
          "text": "run tests: `make test`",
          "source_url": "https://github.com/gojek/ziggurat#L62",
          "evidence": "4. Run tests: `make test`"
        },
        {
          "text": "run `make setup-cluster`",
          "source_url": "https://github.com/gojek/ziggurat#L66",
          "evidence": "- Run `make setup-cluster`. This clears up the volume and starts:"
        },
        {
          "text": "run `make test-cluster`",
          "source_url": "https://github.com/gojek/ziggurat#L73",
          "evidence": "- Run `make test-cluster`. This uses `config.test.cluster.edn` instead of `config.test.edn`."
        },
        {
          "text": "runs at startup goes here",
          "source_url": "https://github.com/gojek/ziggurat#L91",
          "evidence": ";; your logic that runs at startup goes here"
        },
        {
          "text": "runs at shutdown goes here",
          "source_url": "https://github.com/gojek/ziggurat#L95",
          "evidence": ";; your logic that runs at shutdown goes here"
        },
        {
          "text": "track skipped messages",
          "source_url": "https://github.com/gojek/ziggurat#L127",
          "evidence": "- :skip - The message should be skipped without reporting its failure or retrying the message. Same as :success except that a different metric is published to track skipped messages"
        },
        {
          "text": "run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc",
          "source_url": "https://github.com/gojek/ziggurat#L128",
          "evidence": "- The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc."
        },
        {
          "text": "run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc",
          "source_url": "https://github.com/gojek/ziggurat#L129",
          "evidence": "- The stop-fn is run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc."
        },
        {
          "text": "enables reading from multiple streams and applying same/different functions to the messages",
          "source_url": "https://github.com/gojek/ziggurat#L134",
          "evidence": "- Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is a unique identifier per stream which needs to be included in config.edn file"
        },
        {
          "text": "runs at startup goes here",
          "source_url": "https://github.com/gojek/ziggurat#L146",
          "evidence": ";; your logic that runs at startup goes here"
        },
        {
          "text": "runs at shutdown goes here",
          "source_url": "https://github.com/gojek/ziggurat#L150",
          "evidence": ";; your logic that runs at shutdown goes here"
        },
        {
          "text": "Toggle Streams on a Running Actor",
          "source_url": "https://github.com/gojek/ziggurat#L45",
          "evidence": "- [Toggle Streams on a Running Actor](doc/CONCEPTS.md#toggle-streams-in-running-actor)"
        },
        {
          "text": "Run `make setup-cluster`. This clears up the volume and starts:",
          "source_url": "https://github.com/gojek/ziggurat#L66",
          "evidence": "- Run `make setup-cluster`. This clears up the volume and starts:"
        },
        {
          "text": "Run `make test-cluster`. This uses `config.test.cluster.edn` instead of `config.test.edn`.",
          "source_url": "https://github.com/gojek/ziggurat#L73",
          "evidence": "- Run `make test-cluster`. This uses `config.test.cluster.edn` instead of `config.test.edn`."
        },
        {
          "text": "- :success - The message was successfully processed and the stream should continue to the next message",
          "source_url": "https://github.com/gojek/ziggurat#L124",
          "evidence": "- :success - The message was successfully processed and the stream should continue to the next message"
        },
        {
          "text": "- :retry - The message failed to be processed and it should be retried via RabbitMQ.",
          "source_url": "https://github.com/gojek/ziggurat#L125",
          "evidence": "- :retry - The message failed to be processed and it should be retried via RabbitMQ."
        },
        {
          "text": "- :skip - The message should be skipped without reporting its failure or retrying the message. Same as :success except that a different metric is published to track skipped messages",
          "source_url": "https://github.com/gojek/ziggurat#L127",
          "evidence": "- :skip - The message should be skipped without reporting its failure or retrying the message. Same as :success except that a different metric is published to track skipped messages"
        },
        {
          "text": "The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc.",
          "source_url": "https://github.com/gojek/ziggurat#L128",
          "evidence": "- The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc."
        },
        {
          "text": "The stop-fn is run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc.",
          "source_url": "https://github.com/gojek/ziggurat#L129",
          "evidence": "- The stop-fn is run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc."
        },
        {
          "text": "Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is a unique identifier per stream which needs to be included in config.edn file",
          "source_url": "https://github.com/gojek/ziggurat#L134",
          "evidence": "- Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is a unique identifier per stream which needs to be included in config.edn file"
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "aceld/kis-flow",
      "url": "https://github.com/aceld/kis-flow",
      "stars": 402,
      "language": "Go",
      "features": [
        {
          "text": "process while performing various activities or tasks",
          "source_url": "https://github.com/aceld/kis-flow#L13",
          "evidence": "A Streaming Computation Framework Based on Golang. Emphasizes maintaining a simple, clear, and smooth process while performing various activities or tasks."
        },
        {
          "text": "performing various activities or tasks",
          "source_url": "https://github.com/aceld/kis-flow#L13",
          "evidence": "A Streaming Computation Framework Based on Golang. Emphasizes maintaining a simple, clear, and smooth process while performing various activities or tasks."
        },
        {
          "text": "supports a passive consumption mode, providing kisflow with real-time computing capabilities",
          "source_url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        },
        {
          "text": "supports operator expression splicing, connector integration, strategy configuration, stateful function mode, and slink stream splicing",
          "source_url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        },
        {
          "text": "allowing functions to have fixed independent processing capabilities",
          "source_url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        },
        {
          "text": "processing policies for kisfunctions, allowing functions to have fixed independent processing capabilities",
          "source_url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        },
        {
          "text": "provides kisflow's timed task, statistics, and aggregation calculation capabilities",
          "source_url": "https://github.com/aceld/kis-flow#L57",
          "evidence": "| Task Scheduling Layer | Timed task scheduling and execution business logic, including task scheduling platform, executor management, scheduling logs, and user management. Provides KisFlow's timed task, statistics, and aggregation calculation capabilities.  | **The task scheduling platform has a visual interface.**\uff1ancludes running reports, scheduling reports, success rate, task management, configuration management, and GLUE IDE as visual management platforms. <br /><br /> **Executor management KisJobs**: Golang SDK, custom business logic, executor automatic registration, task triggering, termination, and removal.<br /><br /> **Executor scenarios KisScenes**: Logical task sets divided according to business needs.<br /><br /> **Scheduling logs and user management**: Collection of task scheduling logs, detailed scheduling, and scheduling process traces.                                                                              |"
        },
        {
          "text": "create a new flow configuration",
          "source_url": "https://github.com/aceld/kis-flow#L127",
          "evidence": "// Create a new flow configuration"
        },
        {
          "text": "create new function configuration",
          "source_url": "https://github.com/aceld/kis-flow#L130",
          "evidence": "// Create new function configuration"
        },
        {
          "text": "create a new flow",
          "source_url": "https://github.com/aceld/kis-flow#L134",
          "evidence": "// Create a new flow"
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "dimastatz/whisper-flow",
      "url": "https://github.com/dimastatz/whisper-flow",
      "stars": 329,
      "language": "Python",
      "features": [
        {
          "text": "provide the entire audio or video file to whisper, which then converts the speech into text",
          "source_url": "https://github.com/dimastatz/whisper-flow#L15",
          "evidence": "OpenAI [Whisper](https://github.com/openai/whisper) is a versatile speech recognition model designed for general use. Trained on a vast and varied audio dataset, Whisper can handle tasks such as multilingual speech recognition, speech translation, and language identification. It is commonly used for batch transcription, where you provide the entire audio or video file to Whisper, which then converts the speech into text. This process is not done in real-time; instead, Whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later."
        },
        {
          "text": "handle tasks such as multilingual speech recognition, speech translation, and language identification",
          "source_url": "https://github.com/dimastatz/whisper-flow#L15",
          "evidence": "OpenAI [Whisper](https://github.com/openai/whisper) is a versatile speech recognition model designed for general use. Trained on a vast and varied audio dataset, Whisper can handle tasks such as multilingual speech recognition, speech translation, and language identification. It is commonly used for batch transcription, where you provide the entire audio or video file to Whisper, which then converts the speech into text. This process is not done in real-time; instead, Whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later."
        },
        {
          "text": "process is not done in real-time; instead, whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later",
          "source_url": "https://github.com/dimastatz/whisper-flow#L15",
          "evidence": "OpenAI [Whisper](https://github.com/openai/whisper) is a versatile speech recognition model designed for general use. Trained on a vast and varied audio dataset, Whisper can handle tasks such as multilingual speech recognition, speech translation, and language identification. It is commonly used for batch transcription, where you provide the entire audio or video file to Whisper, which then converts the speech into text. This process is not done in real-time; instead, Whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later."
        },
        {
          "text": "generate real-time transcriptions for your media content",
          "source_url": "https://github.com/dimastatz/whisper-flow#L18",
          "evidence": "Using Whisper Flow, you can generate real-time transcriptions for your media content. Unlike batch transcriptions, where media files are uploaded and processed, streaming media is delivered to Whisper Flow in real time, and the service returns a transcript immediately."
        },
        {
          "text": "include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times",
          "source_url": "https://github.com/dimastatz/whisper-flow#L21",
          "evidence": "Streaming content is sent as a series of sequential data packets, or 'chunks,' which Whisper Flow transcribes on the spot. The benefits of using streaming over batch processing include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times. However, this speed may come at the expense of accuracy in some cases."
        },
        {
          "text": "processing include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times",
          "source_url": "https://github.com/dimastatz/whisper-flow#L21",
          "evidence": "Streaming content is sent as a series of sequential data packets, or 'chunks,' which Whisper Flow transcribes on the spot. The benefits of using streaming over batch processing include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times. However, this speed may come at the expense of accuracy in some cases."
        },
        {
          "text": "perform operations on data within specific time frames known as temporal windows",
          "source_url": "https://github.com/dimastatz/whisper-flow#L24",
          "evidence": "In scenarios involving time-streaming, it's typical to perform operations on data within specific time frames known as temporal windows. One common approach is using the [tumbling window](https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions#tumbling-window) technique, which involves gathering events into segments until a certain condition is met."
        },
        {
          "text": "run whisperflow as a web server, start by cloning the repository to your local machine",
          "source_url": "https://github.com/dimastatz/whisper-flow#L98",
          "evidence": "To run WhisperFlow as a web server, start by cloning the repository to your local machine."
        },
        {
          "text": "create a local venv with all dependencies and run the web server on port 8181",
          "source_url": "https://github.com/dimastatz/whisper-flow#L102",
          "evidence": "Then navigate to WhisperFlow folder, create a local venv with all dependencies and run the web server on port 8181."
        },
        {
          "text": "run the web server on port 8181",
          "source_url": "https://github.com/dimastatz/whisper-flow#L102",
          "evidence": "Then navigate to WhisperFlow folder, create a local venv with all dependencies and run the web server on port 8181."
        },
        {
          "text": "handle terminate exception to stop the session and close the connection if needed",
          "source_url": "https://github.com/dimastatz/whisper-flow#L111",
          "evidence": "Set up a WebSocket endpoint for real-time transcription by retrieving the transcription model and creating asynchronous functions for transcribing audio chunks and sending JSON responses. Manage the WebSocket connection by continuously processing incoming audio data. Handle terminate exception to stop the session and close the connection if needed."
        },
        {
          "text": "manage the websocket connection by continuously processing incoming audio data",
          "source_url": "https://github.com/dimastatz/whisper-flow#L111",
          "evidence": "Set up a WebSocket endpoint for real-time transcription by retrieving the transcription model and creating asynchronous functions for transcribing audio chunks and sending JSON responses. Manage the WebSocket connection by continuously processing incoming audio data. Handle terminate exception to stop the session and close the connection if needed."
        },
        {
          "text": "processing incoming audio data",
          "source_url": "https://github.com/dimastatz/whisper-flow#L111",
          "evidence": "Set up a WebSocket endpoint for real-time transcription by retrieving the transcription model and creating asynchronous functions for transcribing audio chunks and sending JSON responses. Manage the WebSocket connection by continuously processing incoming audio data. Handle terminate exception to stop the session and close the connection if needed."
        },
        {
          "text": "import whsiperflow and transcriber modules",
          "source_url": "https://github.com/dimastatz/whisper-flow#L119",
          "evidence": "Now import whsiperflow and transcriber modules"
        },
        {
          "text": "import whisperflow",
          "source_url": "https://github.com/dimastatz/whisper-flow#L122",
          "evidence": "import whisperflow.streaming as st"
        },
        {
          "text": "import whisperflow",
          "source_url": "https://github.com/dimastatz/whisper-flow#L123",
          "evidence": "import whisperflow.transcriber as ts"
        },
        {
          "text": "includes transcription streaming implementation",
          "source_url": "https://github.com/dimastatz/whisper-flow#L147",
          "evidence": "- [X] Release v1.0-RC - Includes transcription streaming implementation."
        },
        {
          "text": "[X] Release v1.0-RC - Includes transcription streaming implementation.",
          "source_url": "https://github.com/dimastatz/whisper-flow#L147",
          "evidence": "- [X] Release v1.0-RC - Includes transcription streaming implementation."
        },
        {
          "text": "[X] Release v1.1 - Bug fixes and implementation of the most requested changes.",
          "source_url": "https://github.com/dimastatz/whisper-flow#L148",
          "evidence": "- [X] Release v1.1 - Bug fixes and implementation of the most requested changes."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "cdapio/tigon",
      "url": "https://github.com/cdapio/tigon",
      "stars": 285,
      "language": "C++",
      "features": [
        {
          "text": "processing framework",
          "source_url": "https://github.com/cdapio/tigon#L7",
          "evidence": "**Tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework."
        },
        {
          "text": "handle a diverse",
          "source_url": "https://github.com/cdapio/tigon#L10",
          "evidence": "technologies from these companies to create a disruptive new framework to handle a diverse"
        },
        {
          "text": "create a disruptive new framework to handle a diverse",
          "source_url": "https://github.com/cdapio/tigon#L10",
          "evidence": "technologies from these companies to create a disruptive new framework to handle a diverse"
        },
        {
          "text": "provides scalable, reliable, and persistent high-throughput",
          "source_url": "https://github.com/cdapio/tigon#L13",
          "evidence": "Cask Data has built technology that provides scalable, reliable, and persistent high-throughput"
        },
        {
          "text": "processing with high-level java apis using hadoop and hbase",
          "source_url": "https://github.com/cdapio/tigon#L14",
          "evidence": "event processing with high-level Java APIs using Hadoop and HBase."
        },
        {
          "text": "provides massively scalable, flexible, and in-memory",
          "source_url": "https://github.com/cdapio/tigon#L16",
          "evidence": "AT&T has built a streaming engine that provides massively scalable, flexible, and in-memory"
        },
        {
          "text": "processing with a sql-like query language",
          "source_url": "https://github.com/cdapio/tigon#L17",
          "evidence": "low-latency stream processing with a SQL-like query Language."
        },
        {
          "text": "handle extremely large data flows;",
          "source_url": "https://github.com/cdapio/tigon#L23",
          "evidence": "- Ability to handle extremely large data flows;"
        },
        {
          "text": "processing using an app-level java api with consistency, reliability, and persistence;",
          "source_url": "https://github.com/cdapio/tigon#L24",
          "evidence": "- Exactly-once event processing using an app-level Java API with consistency, reliability, and persistence;"
        },
        {
          "text": "runs collections of queries using pipelined query plans;",
          "source_url": "https://github.com/cdapio/tigon#L26",
          "evidence": "- Runs collections of queries using pipelined query plans;"
        },
        {
          "text": "handle complex record routing in large parallelized implementations;",
          "source_url": "https://github.com/cdapio/tigon#L27",
          "evidence": "- Able to transparently handle complex record routing in large parallelized implementations;"
        },
        {
          "text": "runs and scales as a native apache hadoop yarn application;",
          "source_url": "https://github.com/cdapio/tigon#L28",
          "evidence": "- Runs and scales as a native Apache Hadoop YARN Application;"
        },
        {
          "text": "integrates with hdfs and hbase;",
          "source_url": "https://github.com/cdapio/tigon#L29",
          "evidence": "- Reads, writes, and tightly integrates with HDFS and HBase;"
        },
        {
          "text": "supports a significant amount of parallelization;",
          "source_url": "https://github.com/cdapio/tigon#L30",
          "evidence": "- Supports a significant amount of parallelization;"
        },
        {
          "text": "monitoring tools; and",
          "source_url": "https://github.com/cdapio/tigon#L32",
          "evidence": "- Enterprise security features with debugging, logging, and monitoring tools; and"
        },
        {
          "text": "run tigon; note that $java_home should be set)",
          "source_url": "https://github.com/cdapio/tigon#L56",
          "evidence": "1. JDK 6 or JDK 7 (required to run Tigon; note that $JAVA_HOME should be set)"
        },
        {
          "text": "build the example applications)",
          "source_url": "https://github.com/cdapio/tigon#L59",
          "evidence": "4. Apache Maven 3.0+ (required to build the example applications)"
        },
        {
          "text": "run the tigonsql stream engine outside of tigon, libz, perl 5",
          "source_url": "https://github.com/cdapio/tigon#L61",
          "evidence": "Note: To run the TigonSQL Stream Engine outside of Tigon, libz, Perl 5.x, and Python 3.x are required."
        },
        {
          "text": "run instructions",
          "source_url": "https://github.com/cdapio/tigon#L72",
          "evidence": "### Run Instructions"
        },
        {
          "text": "run tigon in standalone mode:",
          "source_url": "https://github.com/cdapio/tigon#L74",
          "evidence": "To run Tigon in standalone mode:"
        },
        {
          "text": "run tigon in distributed mode:",
          "source_url": "https://github.com/cdapio/tigon#L78",
          "evidence": "To run Tigon in distributed mode:"
        },
        {
          "text": "building from source",
          "source_url": "https://github.com/cdapio/tigon#L82",
          "evidence": "### Building from Source"
        },
        {
          "text": "build tigon directly from the latest source code:",
          "source_url": "https://github.com/cdapio/tigon#L84",
          "evidence": "You can also build Tigon directly from the latest source code:"
        },
        {
          "text": "build completes, you will have a distribution of tigon under the",
          "source_url": "https://github.com/cdapio/tigon#L90",
          "evidence": "After the build completes, you will have a distribution of Tigon under the"
        },
        {
          "text": "processing application",
          "source_url": "https://github.com/cdapio/tigon#L113",
          "evidence": "Demonstrates using TigonSQL to write a webpage click stream data processing application."
        },
        {
          "text": "processing framework used in the cask data application platform ([cdap](http://cdap",
          "source_url": "https://github.com/cdapio/tigon#L119",
          "evidence": "Tigon is the realtime stream processing framework used in the Cask Data Application Platform ([CDAP](http://cdap.io))."
        },
        {
          "text": "provides a high-level [dataset](http://docs",
          "source_url": "https://github.com/cdapio/tigon#L120",
          "evidence": "CDAP provides a high-level [Dataset](http://docs.cask.co/cdap/current/en/developers-manual/building-blocks/datasets/index.html) abstraction for User Data Stores"
        },
        {
          "text": "allows developers to interact with them in their flowlets",
          "source_url": "https://github.com/cdapio/tigon#L121",
          "evidence": "and allows developers to interact with them in their flowlets. In addition to the Dataset abstraction, CDAP integrates Batch Processing with"
        },
        {
          "text": "integrates batch processing with",
          "source_url": "https://github.com/cdapio/tigon#L121",
          "evidence": "and allows developers to interact with them in their flowlets. In addition to the Dataset abstraction, CDAP integrates Batch Processing with"
        },
        {
          "text": "building phase, similar to apache's",
          "source_url": "https://github.com/cdapio/tigon#L138",
          "evidence": "We have a simple pull-based development model with a consensus-building phase, similar to Apache's"
        },
        {
          "text": "create a topic branch with an appropriate name",
          "source_url": "https://github.com/cdapio/tigon#L146",
          "evidence": "3. Create a topic branch with an appropriate name."
        },
        {
          "text": "create a pull request from your github repo (it\u2019s helpful if you fill in",
          "source_url": "https://github.com/cdapio/tigon#L148",
          "evidence": "5. Once you\u2019re satisfied, create a pull request from your GitHub repo (it\u2019s helpful if you fill in"
        },
        {
          "text": "*Tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework.",
          "source_url": "https://github.com/cdapio/tigon#L7",
          "evidence": "**Tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework."
        },
        {
          "text": "Ability to handle extremely large data flows;",
          "source_url": "https://github.com/cdapio/tigon#L23",
          "evidence": "- Ability to handle extremely large data flows;"
        },
        {
          "text": "Exactly-once event processing using an app-level Java API with consistency, reliability, and persistence;",
          "source_url": "https://github.com/cdapio/tigon#L24",
          "evidence": "- Exactly-once event processing using an app-level Java API with consistency, reliability, and persistence;"
        },
        {
          "text": "Runs collections of queries using pipelined query plans;",
          "source_url": "https://github.com/cdapio/tigon#L26",
          "evidence": "- Runs collections of queries using pipelined query plans;"
        },
        {
          "text": "Able to transparently handle complex record routing in large parallelized implementations;",
          "source_url": "https://github.com/cdapio/tigon#L27",
          "evidence": "- Able to transparently handle complex record routing in large parallelized implementations;"
        },
        {
          "text": "Runs and scales as a native Apache Hadoop YARN Application;",
          "source_url": "https://github.com/cdapio/tigon#L28",
          "evidence": "- Runs and scales as a native Apache Hadoop YARN Application;"
        },
        {
          "text": "Reads, writes, and tightly integrates with HDFS and HBase;",
          "source_url": "https://github.com/cdapio/tigon#L29",
          "evidence": "- Reads, writes, and tightly integrates with HDFS and HBase;"
        },
        {
          "text": "Supports a significant amount of parallelization;",
          "source_url": "https://github.com/cdapio/tigon#L30",
          "evidence": "- Supports a significant amount of parallelization;"
        },
        {
          "text": "Enterprise security features with debugging, logging, and monitoring tools; and",
          "source_url": "https://github.com/cdapio/tigon#L32",
          "evidence": "- Enterprise security features with debugging, logging, and monitoring tools; and"
        },
        {
          "text": "Open-source software and development process.",
          "source_url": "https://github.com/cdapio/tigon#L34",
          "evidence": "- Open-source software and development process."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "zszszszsz/.config",
      "url": "https://github.com/zszszszsz/.config",
      "stars": 285,
      "language": "Shell",
      "features": [
        {
          "text": "build openwrt using github actions",
          "source_url": "https://github.com/zszszszsz/.config#L7",
          "evidence": "Build OpenWrt using GitHub Actions"
        },
        {
          "text": "create a new repository",
          "source_url": "https://github.com/zszszszsz/.config#L13",
          "evidence": "- Click the [Use this template](https://github.com/P3TERX/Actions-OpenWrt/generate) button to create a new repository."
        },
        {
          "text": "build starts automatically",
          "source_url": "https://github.com/zszszszsz/.config#L15",
          "evidence": "- Push `.config` file to the GitHub repository, and the build starts automatically.Progress can be viewed on the Actions page."
        },
        {
          "text": "build is complete, click the `artifacts` button in the upper right corner of the actions page to download the binaries",
          "source_url": "https://github.com/zszszszsz/.config#L16",
          "evidence": "- When the build is complete, click the `Artifacts` button in the upper right corner of the Actions page to download the binaries."
        },
        {
          "text": "create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `actions-openwrt` in github](https://github",
          "source_url": "https://github.com/zszszszsz/.config#L20",
          "evidence": "It may take a long time to create a `.config` file and build the OpenWrt firmware. Thus, before create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `Actions-Openwrt` in GitHub](https://github.com/search?q=Actions-openwrt)."
        },
        {
          "text": "build the openwrt firmware",
          "source_url": "https://github.com/zszszszsz/.config#L20",
          "evidence": "It may take a long time to create a `.config` file and build the OpenWrt firmware. Thus, before create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `Actions-Openwrt` in GitHub](https://github.com/search?q=Actions-openwrt)."
        },
        {
          "text": "build your own firmware, you may check out if others have already built it which meet your needs by simply [search `actions-openwrt` in github](https://github",
          "source_url": "https://github.com/zszszszsz/.config#L20",
          "evidence": "It may take a long time to create a `.config` file and build the OpenWrt firmware. Thus, before create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `Actions-Openwrt` in GitHub](https://github.com/search?q=Actions-openwrt)."
        },
        {
          "text": "Click the Use this template button to create a new repository.",
          "source_url": "https://github.com/zszszszsz/.config#L13",
          "evidence": "- Click the [Use this template](https://github.com/P3TERX/Actions-OpenWrt/generate) button to create a new repository."
        },
        {
          "text": "Generate `.config` files using Lean's OpenWrt source code. ( You can change it through environment variables in the workflow file. )",
          "source_url": "https://github.com/zszszszsz/.config#L14",
          "evidence": "- Generate `.config` files using [Lean's OpenWrt](https://github.com/coolsnowwolf/lede) source code. ( You can change it through environment variables in the workflow file. )"
        },
        {
          "text": "Push `.config` file to the GitHub repository, and the build starts automatically.Progress can be viewed on the Actions page.",
          "source_url": "https://github.com/zszszszsz/.config#L15",
          "evidence": "- Push `.config` file to the GitHub repository, and the build starts automatically.Progress can be viewed on the Actions page."
        },
        {
          "text": "When the build is complete, click the `Artifacts` button in the upper right corner of the Actions page to download the binaries.",
          "source_url": "https://github.com/zszszszsz/.config#L16",
          "evidence": "- When the build is complete, click the `Artifacts` button in the upper right corner of the Actions page to download the binaries."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "raystack/dagger",
      "url": "https://github.com/raystack/dagger",
      "stars": 276,
      "language": "Java",
      "features": [
        {
          "text": "Processing: Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical.",
          "source_url": "https://github.com/raystack/dagger#L18",
          "evidence": "- **Processing:** Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical."
        },
        {
          "text": "Scale: Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops.",
          "source_url": "https://github.com/raystack/dagger#L19",
          "evidence": "- **Scale:** Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops."
        },
        {
          "text": "Extensibility: Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources.",
          "source_url": "https://github.com/raystack/dagger#L20",
          "evidence": "- **Extensibility:** Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources."
        },
        {
          "text": "Flexibility: Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic.",
          "source_url": "https://github.com/raystack/dagger#L21",
          "evidence": "- **Flexibility:** Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic."
        },
        {
          "text": "Metrics: Always know what\u2019s going on with your deployment with built-in monitoring of throughput, response times, errors and more.",
          "source_url": "https://github.com/raystack/dagger#L22",
          "evidence": "- **Metrics:** Always know what\u2019s going on with your deployment with built-in [monitoring](https://raystack.github.io/dagger/docs/reference/metrics) of throughput, response times, errors and more."
        },
        {
          "text": "build workflow](https://github",
          "source_url": "https://github.com/raystack/dagger#L3",
          "evidence": "![build workflow](https://github.com/raystack/dagger/actions/workflows/build.yml/badge.svg)"
        },
        {
          "text": "processing of data",
          "source_url": "https://github.com/raystack/dagger#L9",
          "evidence": "for stateful processing of data. With Dagger, you don't need to write custom applications or complicated code to process"
        },
        {
          "text": "processing and analysis on streaming data",
          "source_url": "https://github.com/raystack/dagger#L10",
          "evidence": "data as a stream. Instead, you can write SQL queries and UDFs to do the processing and analysis on streaming data."
        },
        {
          "text": "plugins \\(udfs, transformers, preprocessors and post processors\\) independent of the core logic",
          "source_url": "https://github.com/raystack/dagger#L21",
          "evidence": "- **Flexibility:** Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic."
        },
        {
          "text": "processing -> [longbow](https://raystack",
          "source_url": "https://github.com/raystack/dagger#L31",
          "evidence": "- Realtime long window processing -> [Longbow](https://raystack.github.io/dagger/docs/advance/longbow)"
        },
        {
          "text": "provides guidance on [creating dagger](https://raystack",
          "source_url": "https://github.com/raystack/dagger#L39",
          "evidence": "- [Guides](https://raystack.github.io/dagger/docs/guides/overview) provides guidance on [creating Dagger](https://raystack.github.io/dagger/docs/guides/create_dagger) with different sinks."
        },
        {
          "text": "run code quality checks",
          "source_url": "https://github.com/raystack/dagger#L65",
          "evidence": "# Run code quality checks"
        },
        {
          "text": "build and test your changes to dagger",
          "source_url": "https://github.com/raystack/dagger#L76",
          "evidence": "Read our [contributing guide](https://raystack.github.io/dagger/docs/contribute/contribution) to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes to Dagger."
        },
        {
          "text": "Processing: Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical.",
          "source_url": "https://github.com/raystack/dagger#L18",
          "evidence": "- **Processing:** Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical."
        },
        {
          "text": "Scale: Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops.",
          "source_url": "https://github.com/raystack/dagger#L19",
          "evidence": "- **Scale:** Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops."
        },
        {
          "text": "Extensibility: Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources.",
          "source_url": "https://github.com/raystack/dagger#L20",
          "evidence": "- **Extensibility:** Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources."
        },
        {
          "text": "Flexibility: Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic.",
          "source_url": "https://github.com/raystack/dagger#L21",
          "evidence": "- **Flexibility:** Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic."
        },
        {
          "text": "Metrics: Always know what\u2019s going on with your deployment with built-in monitoring of throughput, response times, errors and more.",
          "source_url": "https://github.com/raystack/dagger#L22",
          "evidence": "- **Metrics:** Always know what\u2019s going on with your deployment with built-in [monitoring](https://raystack.github.io/dagger/docs/reference/metrics) of throughput, response times, errors and more."
        },
        {
          "text": "Enrichment -> Post Processors",
          "source_url": "https://github.com/raystack/dagger#L27",
          "evidence": "- Enrichment -> [Post Processors](https://raystack.github.io/dagger/docs/advance/post_processor)"
        },
        {
          "text": "Realtime long window processing -> Longbow",
          "source_url": "https://github.com/raystack/dagger#L31",
          "evidence": "- Realtime long window processing -> [Longbow](https://raystack.github.io/dagger/docs/advance/longbow)"
        },
        {
          "text": "Guides provides guidance on creating Dagger with different sinks.",
          "source_url": "https://github.com/raystack/dagger#L39",
          "evidence": "- [Guides](https://raystack.github.io/dagger/docs/guides/overview) provides guidance on [creating Dagger](https://raystack.github.io/dagger/docs/guides/create_dagger) with different sinks."
        },
        {
          "text": "Concepts describes all important Dagger concepts.",
          "source_url": "https://github.com/raystack/dagger#L40",
          "evidence": "- [Concepts](https://raystack.github.io/dagger/docs/concepts/overview) describes all important Dagger concepts."
        },
        {
          "text": "*Note:** Sample configuration for running a basic dagger can be found here. For detailed configurations, refer here.",
          "source_url": "https://github.com/raystack/dagger#L51",
          "evidence": "**Note:** Sample configuration for running a basic dagger can be found [here](https://raystack.github.io/dagger/docs/guides/create_dagger#common-configurations). For detailed configurations, refer [here](https://raystack.github.io/dagger/docs/reference/configuration)."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "molyswu/hand_detection",
      "url": "https://github.com/molyswu/hand_detection",
      "stars": 264,
      "language": "Python",
      "features": [
        {
          "text": "process has to do with finding or creating the right (annotated) dataset",
          "source_url": "https://github.com/molyswu/hand_detection#L3",
          "evidence": "This repo documents steps and scripts used to train a hand detector using Tensorflow (Object Detection API). As with any DNN based task, the most expensive (and riskiest) part of the process has to do with finding or creating the right (annotated) dataset. I was interested mainly in detecting hands on a table (egocentric view point). I experimented first with the [Oxford Hands Dataset](http://www.robots.ox.ac.uk/~vgg/data/hands/) (the results were not good). I then tried the [Egohands Dataset](http://vision.soic.indiana.edu/projects/egohands/) which was a much better fit to my requirements."
        },
        {
          "text": "provide code that can be adapted to other uses cases",
          "source_url": "https://github.com/molyswu/hand_detection#L5",
          "evidence": "The goal of this repo/post is to demonstrate how neural networks can be applied to the (hard) problem of tracking hands (egocentric and other views). Better still, provide code that can be adapted to other uses cases."
        },
        {
          "text": "tracking hands (egocentric and other views)",
          "source_url": "https://github.com/molyswu/hand_detection#L5",
          "evidence": "The goal of this repo/post is to demonstrate how neural networks can be applied to the (hard) problem of tracking hands (egocentric and other views). Better still, provide code that can be adapted to other uses cases."
        },
        {
          "text": "run on a macbook pro cpu (i7, 2",
          "source_url": "https://github.com/molyswu/hand_detection#L17",
          "evidence": "Both examples above were run on a macbook pro **CPU** (i7, 2.5GHz, 16GB). Some fps numbers are:"
        },
        {
          "text": "run without visualizing results|",
          "source_url": "https://github.com/molyswu/hand_detection#L22",
          "evidence": "| 21  | 320 * 240  | Macbook pro (i7, 2.5GHz, 16GB) | Run without visualizing results|"
        },
        {
          "text": "run while visualizing results (image above) |",
          "source_url": "https://github.com/molyswu/hand_detection#L23",
          "evidence": "| 16  | 320 * 240  | Macbook pro (i7, 2.5GHz, 16GB) | Run while visualizing results (image above) |"
        },
        {
          "text": "run while visualizing results (image above) |",
          "source_url": "https://github.com/molyswu/hand_detection#L24",
          "evidence": "| 11  | 640 * 480  | Macbook pro (i7, 2.5GHz, 16GB) | Run while visualizing results (image above) |"
        },
        {
          "text": "generate your own frozen model](https://pythonprogramming",
          "source_url": "https://github.com/molyswu/hand_detection#L27",
          "evidence": "You may need to [generate your own frozen model](https://pythonprogramming.net/testing-custom-object-detector-tensorflow-object-detection-api-tutorial/?completed=/training-custom-objects-tensorflow-object-detection-api-tutorial/) graph using the [model checkpoints](model-checkpoint) in the repo to fit your TF version."
        },
        {
          "text": "tracking hands in the computer vision domain",
          "source_url": "https://github.com/molyswu/hand_detection#L42",
          "evidence": "There are several existing approaches to tracking hands in the computer vision domain. Incidentally, many of these approaches are rule based (e.g extracting background based on texture and boundary features, distinguishing between hands and background using color histograms and HOG classifiers,) making them not very robust. For example, these algorithms might get confused if the background is unusual or in situations where sharp changes in lighting conditions cause sharp changes in skin color or the tracked object becomes occluded.(see [here for a review](https://www.cse.unr.edu/~bebis/handposerev.pdf) paper on hand pose estimation from the HCI perspective)"
        },
        {
          "text": "provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion",
          "source_url": "https://github.com/molyswu/hand_detection#L44",
          "evidence": "With sufficiently large datasets, neural networks provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion. The main drawbacks to usage for real-time tracking/detection is that they can be complex, are relatively slow compared to tracking-only algorithms and it can be quite expensive to assemble a good dataset. But things are changing with advances in fast neural networks."
        },
        {
          "text": "perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion",
          "source_url": "https://github.com/molyswu/hand_detection#L44",
          "evidence": "With sufficiently large datasets, neural networks provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion. The main drawbacks to usage for real-time tracking/detection is that they can be complex, are relatively slow compared to tracking-only algorithms and it can be quite expensive to assemble a good dataset. But things are changing with advances in fast neural networks."
        },
        {
          "text": "process of training a model for custom object detection",
          "source_url": "https://github.com/molyswu/hand_detection#L46",
          "evidence": "Furthermore, this entire area of work has been made more approachable by deep learning frameworks (such as the tensorflow object detection api) that simplify the process of training a model for custom object detection. More importantly, the advent of fast neural network models like ssd, faster r-cnn, rfcn (see [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models) ) etc make neural networks an attractive candidate for real-time detection (and tracking) applications. Hopefully, this repo demonstrates this."
        },
        {
          "text": "provide in detecting hands](#detecting-hands)",
          "source_url": "https://github.com/molyswu/hand_detection#L48",
          "evidence": "> If you are not interested in the process of training the detector, you can skip straight to applying the [pretrained model I provide in detecting hands](#detecting-hands)."
        },
        {
          "text": "process of training the detector, you can skip straight to applying the pretrained model i provide in detecting hands",
          "source_url": "https://github.com/molyswu/hand_detection#L48",
          "evidence": "> If you are not interested in the process of training the detector, you can skip straight to applying the [pretrained model I provide in detecting hands](#detecting-hands)."
        },
        {
          "text": "process (assembling dataset, cleaning, splitting into training/test partitions and generating an inference graph)",
          "source_url": "https://github.com/molyswu/hand_detection#L50",
          "evidence": "Training a model is a multi-stage process (assembling dataset, cleaning, splitting into training/test partitions and generating an inference graph). While I lightly touch on the details of these parts, there are a few other tutorials cover training a custom object detector using the tensorflow object detection api in more detail[ see [here](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) and [here](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9) ]. I recommend you walk through those if interested in training a custom object detector from scratch."
        },
        {
          "text": "generate these csv files",
          "source_url": "https://github.com/molyswu/hand_detection#L82",
          "evidence": "Some initial work needs to be done to the Egohands dataset to transform it into the format (`tfrecord`) which Tensorflow needs to train a model. This repo contains `egohands_dataset_clean.py` a script that will help you generate these csv files."
        },
        {
          "text": "include their directory names to ensure each filename is unique",
          "source_url": "https://github.com/molyswu/hand_detection#L85",
          "evidence": "- Renames all files to include their directory names to ensure each filename is unique"
        },
        {
          "text": "generates bounding boxes and visualizes them to ensure correctness (see image above)",
          "source_url": "https://github.com/molyswu/hand_detection#L87",
          "evidence": "- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above)."
        },
        {
          "text": "visualizes them to ensure correctness (see image above)",
          "source_url": "https://github.com/molyswu/hand_detection#L87",
          "evidence": "- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above)."
        },
        {
          "text": "generate `tfrecords`",
          "source_url": "https://github.com/molyswu/hand_detection#L88",
          "evidence": "- Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv`  that can be used to generate `tfrecords`"
        },
        {
          "text": "support 4 labels",
          "source_url": "https://github.com/molyswu/hand_detection#L90",
          "evidence": "Note: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels."
        },
        {
          "text": "provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, i am only interested in the general `hand` class and label all training data as `hand`",
          "source_url": "https://github.com/molyswu/hand_detection#L90",
          "evidence": "Note: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels."
        },
        {
          "text": "generate `tfrecords` that support 4 labels",
          "source_url": "https://github.com/molyswu/hand_detection#L90",
          "evidence": "Note: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels."
        },
        {
          "text": "generate  `train",
          "source_url": "https://github.com/molyswu/hand_detection#L92",
          "evidence": "Next: convert your dataset + csv files to tfrecords. A helpful guide on this can be found [here](https://pythonprogramming.net/creating-tfrecord-files-tensorflow-object-detection-api-tutorial/).For each folder, you should be able to generate  `train.record`, `test.record` required in the training process."
        },
        {
          "text": "offer a few models (in the tensorflow [model zoo](https://github",
          "source_url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        },
        {
          "text": "process called [transfer learning](https://www",
          "source_url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        },
        {
          "text": "process can be done locally on your cpu machine which may take a while or better on a (cloud) gpu machine (which is what i did)",
          "source_url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        },
        {
          "text": "run 200k steps on my mac (i7, 2",
          "source_url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        },
        {
          "text": "process if training locally",
          "source_url": "https://github.com/molyswu/hand_detection#L99",
          "evidence": "> **Training on your own images**: Please use the [guide provided by Harrison from pythonprogramming](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) on how to generate tfrecords given your label csv files and your images. The guide also covers how to start the training process if training locally. [see [here] (https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/)]. If training in the cloud using a service like GCP, see the [guide here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md)."
        },
        {
          "text": "generate tfrecords given your label csv files and your images",
          "source_url": "https://github.com/molyswu/hand_detection#L99",
          "evidence": "> **Training on your own images**: Please use the [guide provided by Harrison from pythonprogramming](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) on how to generate tfrecords given your label csv files and your images. The guide also covers how to start the training process if training locally. [see [here] (https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/)]. If training in the cloud using a service like GCP, see the [guide here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md)."
        },
        {
          "text": "process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout)",
          "source_url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        },
        {
          "text": "process is complete (total loss does not decrease with further iterations/steps)",
          "source_url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        },
        {
          "text": "generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset",
          "source_url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        },
        {
          "text": "run an evaluation concurrently that assesses your model to see how well it performs on the test data",
          "source_url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        },
        {
          "text": "performs on the test data",
          "source_url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        },
        {
          "text": "visualize detected bounding detection_boxes",
          "source_url": "https://github.com/molyswu/hand_detection#L132",
          "evidence": "- Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method."
        },
        {
          "text": "visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc",
          "source_url": "https://github.com/molyswu/hand_detection#L137",
          "evidence": "- detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc."
        },
        {
          "text": "run detection on video at path \"videos/chess",
          "source_url": "https://github.com/molyswu/hand_detection#L142",
          "evidence": "# load and run detection on video at path \"videos/chess.mov\""
        },
        {
          "text": "generate a new graph that fits your tf version from the model-checkpoint in this repo",
          "source_url": "https://github.com/molyswu/hand_detection#L146",
          "evidence": "> Update: If you do have errors loading the frozen inference graph in this repo, feel free to generate a new graph that fits your TF version from the model-checkpoint in this repo."
        },
        {
          "text": "run on the main application thread can slow down the program",
          "source_url": "https://github.com/molyswu/hand_detection#L153",
          "evidence": "- Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from [Adrian Rosebuck](https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/) on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points."
        },
        {
          "text": "tracking algorithms with the already decent detection and this is something i am still experimenting with",
          "source_url": "https://github.com/molyswu/hand_detection#L162",
          "evidence": "Performance can also be increased by a clever combination of tracking algorithms with the already decent detection and this is something I am still experimenting with. Have ideas for optimizing better, please share!"
        },
        {
          "text": "includes non-egocentric viewpoints, very noisy backgrounds (e",
          "source_url": "https://github.com/molyswu/hand_detection#L165",
          "evidence": "Note: The detector does reflect some limitations associated with the training set. This includes non-egocentric viewpoints, very noisy backgrounds (e.g in a sea of hands) and sometimes skin tone.  There is opportunity to improve these with additional data."
        },
        {
          "text": "integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects",
          "source_url": "https://github.com/molyswu/hand_detection#L170",
          "evidence": "One way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process."
        },
        {
          "text": "process of assembling datasets for each class and a lengthy training process",
          "source_url": "https://github.com/molyswu/hand_detection#L170",
          "evidence": "One way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process."
        },
        {
          "text": "create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process",
          "source_url": "https://github.com/molyswu/hand_detection#L170",
          "evidence": "One way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process."
        },
        {
          "text": "allow us efficiently interleave output form multiple pretrained models for various object classes and have them detect multiple objects on a single image",
          "source_url": "https://github.com/molyswu/hand_detection#L172",
          "evidence": "> Given the above, a potential strategy is to explore structures that allow us **efficiently** interleave output form multiple pretrained models for various object classes and have them detect multiple objects on a single image."
        },
        {
          "text": "Motivation - Why Track/Detect hands with Neural Networks",
          "source_url": "https://github.com/molyswu/hand_detection#L32",
          "evidence": "- Motivation - Why Track/Detect hands with Neural Networks"
        },
        {
          "text": "Data preparation and network training in Tensorflow (Dataset, Import, Training)",
          "source_url": "https://github.com/molyswu/hand_detection#L33",
          "evidence": "- Data preparation and network training in Tensorflow (Dataset, Import, Training)"
        },
        {
          "text": "Using the Detector to Detect/Track hands",
          "source_url": "https://github.com/molyswu/hand_detection#L35",
          "evidence": "- Using the Detector to Detect/Track hands"
        },
        {
          "text": "Renames all files to include their directory names to ensure each filename is unique",
          "source_url": "https://github.com/molyswu/hand_detection#L85",
          "evidence": "- Renames all files to include their directory names to ensure each filename is unique"
        },
        {
          "text": "Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above).",
          "source_url": "https://github.com/molyswu/hand_detection#L87",
          "evidence": "- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above)."
        },
        {
          "text": "Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv`  that can be used to generate `tfrecords`",
          "source_url": "https://github.com/molyswu/hand_detection#L88",
          "evidence": "- Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv`  that can be used to generate `tfrecords`"
        },
        {
          "text": "Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method.",
          "source_url": "https://github.com/molyswu/hand_detection#L132",
          "evidence": "- Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method."
        },
        {
          "text": "detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc.",
          "source_url": "https://github.com/molyswu/hand_detection#L137",
          "evidence": "- detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc."
        },
        {
          "text": "Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from Adrian Rosebuck on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points.",
          "source_url": "https://github.com/molyswu/hand_detection#L153",
          "evidence": "- Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from [Adrian Rosebuck](https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/) on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points."
        },
        {
          "text": "Keeping your input image small will increase fps without any significant accuracy drop.(I used about 320 x 240 compared to the 1280 x 720 which my webcam provides).",
          "source_url": "https://github.com/molyswu/hand_detection#L158",
          "evidence": "- Keeping your input image small will increase fps without any significant accuracy drop.(I used about 320 x 240 compared to the 1280 x 720 which my webcam provides)."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    },
    {
      "name": "cross-platform/dspatch",
      "url": "https://github.com/cross-platform/dspatch",
      "stars": 248,
      "language": "C++",
      "features": [
        {
          "text": "build & test](https://github",
          "source_url": "https://github.com/cross-platform/dspatch#L1",
          "evidence": "[![Build & Test](https://github.com/cross-platform/dspatch/actions/workflows/build_and_test.yml/badge.svg)](https://github.com/cross-platform/dspatch/actions/workflows/build_and_test.yml)"
        },
        {
          "text": "allows you to create virtually any graph processing system imaginable",
          "source_url": "https://github.com/cross-platform/dspatch#L9",
          "evidence": "DSPatch, pronounced \"dispatch\", is a powerful C++ dataflow framework. DSPatch is not limited to any particular domain or data type, from reactive programming to stream processing, DSPatch's generic, object-oriented API allows you to create virtually any graph processing system imaginable."
        },
        {
          "text": "processing system imaginable",
          "source_url": "https://github.com/cross-platform/dspatch#L9",
          "evidence": "DSPatch, pronounced \"dispatch\", is a powerful C++ dataflow framework. DSPatch is not limited to any particular domain or data type, from reactive programming to stream processing, DSPatch's generic, object-oriented API allows you to create virtually any graph processing system imaginable."
        },
        {
          "text": "create virtually any graph processing system imaginable",
          "source_url": "https://github.com/cross-platform/dspatch#L9",
          "evidence": "DSPatch, pronounced \"dispatch\", is a powerful C++ dataflow framework. DSPatch is not limited to any particular domain or data type, from reactive programming to stream processing, DSPatch's generic, object-oriented API allows you to create virtually any graph processing system imaginable."
        },
        {
          "text": "build it into your own projects, all you'll need are the files under `include`",
          "source_url": "https://github.com/cross-platform/dspatch#L22",
          "evidence": "DSPatch is a header-only library, to build it into your own projects, all you'll need are the files under `include`."
        },
        {
          "text": "build the tests and tutorial projects:",
          "source_url": "https://github.com/cross-platform/dspatch#L24",
          "evidence": "To build the tests and tutorial projects:"
        },
        {
          "text": "building dspatch circuits",
          "source_url": "https://github.com/cross-platform/dspatch#L35",
          "evidence": "DSPatcher (https://github.com/cross-platform/dspatcher): A cross-platform graphical tool for building DSPatch circuits."
        }
      ],
      "feature_count": 0,
      "coverage": 0.0
    }
  ],
  "features": [
    {
      "text": "A wide range of connectors: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.",
      "normalized_text": "A wide range of connectors: pathway comes with connectors that connect to external data sources such as kafka, gdrive...",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Stateless and stateful transformations: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.",
      "normalized_text": "Stateless and stateful transformations: pathway supports stateful transformations such as joins, windowing, and sorti...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Persistence: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway",
      "normalized_text": "Persistence: pathway provides persistence to save the state of the computation. this allows you to restart your pipel...",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Consistency: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency.",
      "normalized_text": "Consistency: pathway handles the time for you, making sure all your computations are consistent. in particular, pathw...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        }
      ],
      "frequency": 3,
      "uniqueness_score": 0.3333333333333333
    },
    {
      "text": "Scalable Rust engine: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can do multithreading, multiprocessing, and distributed computations.",
      "normalized_text": "Scalable rust engine: with pathway rust engine, you are free from the usual limits imposed by python. you can do mult...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L97",
          "evidence": "- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L97",
          "evidence": "- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "LLM helpers: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can build and deploy RAG applications with your live documents.",
      "normalized_text": "Llm helpers: pathway provides an llm extension with all the utilities to integrate llms with your data pipelines (llm...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        }
      ],
      "frequency": 3,
      "uniqueness_score": 0.3333333333333333
    },
    {
      "text": "allowing you to seamlessly integrate your favorite python ml libraries",
      "normalized_text": "Allowing you to seamlessly integrate your favorite python ml libraries",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L46",
          "evidence": "Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L46",
          "evidence": "Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "processing data streams",
      "normalized_text": "Processing data streams",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L48",
          "evidence": "The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "performs incremental computation",
      "normalized_text": "Performs incremental computation",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L50",
          "evidence": "Pathway is powered by a **scalable Rust engine** based on Differential Dataflow and performs incremental computation."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run by the rust engine, enabling multithreading, multiprocessing, and distributed computations",
      "normalized_text": "Run by the rust engine, enabling multithreading, multiprocessing, and distributed computations",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L51",
          "evidence": "Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run examples](https://pathway",
      "normalized_text": "Run examples](https://pathway",
      "category": "Documentation",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L65",
          "evidence": "[Try one of our easy-to-run examples](https://pathway.com/developers/templates)!"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing and real-time analytics pipelines",
      "normalized_text": "Processing and real-time analytics pipelines",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L69",
          "evidence": "### Event processing and real-time analytics pipelines"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing as easy as possible",
      "normalized_text": "Processing as easy as possible",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L70",
          "evidence": "With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing pipelines, including:",
      "normalized_text": "Processing pipelines, including:",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L70",
          "evidence": "With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L12",
          "evidence": "* event processing pipelines"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "provides dedicated llm tooling to build live llm and rag pipelines",
      "normalized_text": "Provides dedicated llm tooling to build live llm and rag pipelines",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L81",
          "evidence": "Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build live llm and rag pipelines",
      "normalized_text": "Build live llm and rag pipelines",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L81",
          "evidence": "Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allows you to connect to more than 300 different data sources",
      "normalized_text": "Allows you to connect to more than 300 different data sources",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build your own custom connector using pathway python connector",
      "normalized_text": "Build your own custom connector using pathway python connector",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L93",
          "evidence": "- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports stateful transformations such as joins, windowing, and sorting",
      "normalized_text": "Supports stateful transformations such as joins, windowing, and sorting",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides many transformations directly implemented in rust",
      "normalized_text": "Provides many transformations directly implemented in rust",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "implement your own or you can use any python library to process your data",
      "normalized_text": "Implement your own or you can use any python library to process your data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing of data",
      "normalized_text": "Processing of data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L94",
          "evidence": "- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data."
        },
        {
          "url": "https://github.com/raystack/dagger#L9",
          "evidence": "for stateful processing of data. With Dagger, you don't need to write custom applications or complicated code to process"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "provides persistence to save the state of the computation",
      "normalized_text": "Provides persistence to save the state of the computation",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allows you to restart your pipeline after an update or a crash",
      "normalized_text": "Allows you to restart your pipeline after an update or a crash",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L95",
          "evidence": "- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides the \"exactly once\" consistency",
      "normalized_text": "Provides the \"exactly once\" consistency",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system",
      "normalized_text": "Manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come in...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L96",
          "evidence": "- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the \"at least once\" consistency while the enterprise version provides the \"exactly once\" consistency."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "integrate llms with your data pipelines (llm wrappers, parsers, embedders, splitters), including an in-memory real-time vector index, and integrations with llamaindex and langchain",
      "normalized_text": "Integrate llms with your data pipelines (llm wrappers, parsers, embedders, splitters), including an in-memory real-ti...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build and deploy rag applications with your live documents",
      "normalized_text": "Build and deploy rag applications with your live documents",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L98",
          "evidence": "- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run pathway on a virtual machine",
      "normalized_text": "Run pathway on a virtual machine",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L113",
          "evidence": "\u26a0\ufe0f Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "import pathway as pw",
      "normalized_text": "Import pathway as pw",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L119",
          "evidence": "import pathway as pw"
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L156",
          "evidence": "import pathway as pw"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "run the computation",
      "normalized_text": "Run the computation",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L140",
          "evidence": "# Run the computation"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run pathway [in google colab](https://colab",
      "normalized_text": "Run pathway [in google colab](https://colab",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L144",
          "evidence": "Run Pathway [in Google Colab](https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "handle the updates",
      "normalized_text": "Handle the updates",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L159",
          "evidence": "Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create your processing pipeline, and let pathway handle the updates",
      "normalized_text": "Create your processing pipeline, and let pathway handle the updates",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L159",
          "evidence": "Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:"
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L159",
          "evidence": "Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "run your pathway project (say, `main",
      "normalized_text": "Run your pathway project (say, `main",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L165",
          "evidence": "You can then run your Pathway project (say, `main.py`) just like a normal Python script: `$ python main.py`."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system",
      "normalized_text": "Monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency o...",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        }
      ],
      "frequency": 3,
      "uniqueness_score": 0.3333333333333333
    },
    {
      "text": "includes log messages",
      "normalized_text": "Includes log messages",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L166",
          "evidence": "Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports multithreading",
      "normalized_text": "Supports multithreading",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L176",
          "evidence": "Pathway natively supports multithreading."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run pathway using docker",
      "normalized_text": "Run pathway using docker",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L187",
          "evidence": "You can easily run Pathway using docker."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run pip install --no-cache-dir -r requirements",
      "normalized_text": "Run pip install --no-cache-dir -r requirements",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L199",
          "evidence": "RUN pip install --no-cache-dir -r requirements.txt"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build and run the docker image:",
      "normalized_text": "Build and run the docker image:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L206",
          "evidence": "You can then build and run the Docker image:"
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L206",
          "evidence": "You can then build and run the Docker image:"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "build -t my-pathway-app",
      "normalized_text": "Build -t my-pathway-app",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L209",
          "evidence": "docker build -t my-pathway-app ."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run -it --rm --name my-pathway-app my-pathway-app",
      "normalized_text": "Run -it --rm --name my-pathway-app my-pathway-app",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L210",
          "evidence": "docker run -it --rm --name my-pathway-app my-pathway-app"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run a single python script",
      "normalized_text": "Run a single python script",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L213",
          "evidence": "#### Run a single Python script"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run -it --rm --name my-pathway-app -v \"$pwd\":/app pathwaycom/pathway:latest python my-pathway-app",
      "normalized_text": "Run -it --rm --name my-pathway-app -v \"$pwd\":/app pathwaycom/pathway:latest python my-pathway-app",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L220",
          "evidence": "docker run -it --rm --name my-pathway-app -v \"$PWD\":/app pathwaycom/pathway:latest python my-pathway-app.py"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run pip install -u pathway",
      "normalized_text": "Run pip install -u pathway",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L230",
          "evidence": "RUN pip install -U pathway"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing and real time intelligent analytics",
      "normalized_text": "Processing and real time intelligent analytics",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L240",
          "evidence": "Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports distributed kubernetes deployment, with external persistence setup",
      "normalized_text": "Supports distributed kubernetes deployment, with external persistence setup",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L241",
          "evidence": "It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "implement a lot of algorithms/udf's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines)",
      "normalized_text": "Implement a lot of algorithms/udf's in streaming mode which are not readily supported by other streaming frameworks (...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L249",
          "evidence": "Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing tasks, including: flink, spark, and kafka streaming",
      "normalized_text": "Processing tasks, including: flink, spark, and kafka streaming",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L249",
          "evidence": "Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing pipelines and co-promote solutions that push the boundaries of what's possible with python and streaming data",
      "normalized_text": "Processing pipelines and co-promote solutions that push the boundaries of what's possible with python and streaming data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L265",
          "evidence": "We build cutting-edge data processing pipelines and co-promote solutions that push the boundaries of what's possible with Python and streaming data."
        },
        {
          "url": "https://github.com/pathwaycom/pathway#L265",
          "evidence": "We build cutting-edge data processing pipelines and co-promote solutions that push the boundaries of what's possible with Python and streaming data."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "building context-aware ai agents",
      "normalized_text": "Building context-aware ai agents",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L274",
          "evidence": "| [LlamaIndex](https://developers.llamaindex.ai/python/examples/retrievers/pathway_retriever/) | The developer-trusted framework for building context-aware AI agents. |"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "offering end-to-end solutions from text extraction to intelligent document understanding",
      "normalized_text": "Offering end-to-end solutions from text extraction to intelligent document understanding",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L276",
          "evidence": "| [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) | PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding. |"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allows for unlimited non-commercial use, as well as use of the pathway package [for most commercial purposes](https://pathway",
      "normalized_text": "Allows for unlimited non-commercial use, as well as use of the pathway package [for most commercial purposes](https:/...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L283",
          "evidence": "Pathway is distributed on a [BSL 1.1 License](https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt) which allows for unlimited non-commercial use, as well as use of the Pathway package [for most commercial purposes](https://pathway.com/license/), free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some [public repos](https://github.com/pathwaycom) which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "integrate with this repo, we suggest releasing it first as a separate repo on a mit/apache 2",
      "normalized_text": "Integrate with this repo, we suggest releasing it first as a separate repo on a mit/apache 2",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/pathwaycom/pathway#L288",
          "evidence": "If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides a development framework for developing stream processing applications using apache flink and apache spark, alongside a professional management platform",
      "normalized_text": "Provides a development framework for developing stream processing applications using apache flink and apache spark, a...",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L32",
          "evidence": "**StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing applications using apache flink and apache spark, alongside a professional management platform",
      "normalized_text": "Processing applications using apache flink and apache spark, alongside a professional management platform",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L32",
          "evidence": "**StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides a streaming-application framework to accelerate apache flink and spark development, offering prebuilt plug-and-play apis and connectors",
      "normalized_text": "Provides a streaming-application framework to accelerate apache flink and spark development, offering prebuilt plug-a...",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L35",
          "evidence": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors."
        },
        {
          "url": "https://github.com/apache/streampark#L35",
          "evidence": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "offering prebuilt plug-and-play apis and connectors",
      "normalized_text": "Offering prebuilt plug-and-play apis and connectors",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L35",
          "evidence": "* Provides a streaming-application framework to accelerate Apache Flink and Spark development, offering prebuilt plug-and-play APIs and connectors."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more",
      "normalized_text": "Provides a one-stop solution for real-time computing, including application development, deployment, management, moni...",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L37",
          "evidence": "* Provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more."
        },
        {
          "url": "https://github.com/apache/streampark#L37",
          "evidence": "* Provides a one-stop solution for real-time computing, including application development, deployment, management, monitoring, and more."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "supports batch & streaming**",
      "normalized_text": "Supports batch & streaming**",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L38",
          "evidence": "* **Supports Batch & Streaming**"
        },
        {
          "url": "https://github.com/apache/streampark#L38",
          "evidence": "* **Supports Batch & Streaming**"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing.",
      "normalized_text": "* supports apache flink and apache spark, enabling both stream processing and batch processing.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L39",
          "evidence": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing."
        },
        {
          "url": "https://github.com/apache/streampark#L39",
          "evidence": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "processing and batch processing",
      "normalized_text": "Processing and batch processing",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L39",
          "evidence": "* Supports Apache Flink and Apache Spark, enabling both stream processing and batch processing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports multi-engine/multi-version**",
      "normalized_text": "Supports multi-engine/multi-version**",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L40",
          "evidence": "* **Supports Multi-engine/Multi-version**"
        },
        {
          "url": "https://github.com/apache/streampark#L40",
          "evidence": "* **Supports Multi-engine/Multi-version**"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "enables cross-version development and management of apache flink and apache spark applications within a unified framework",
      "normalized_text": "Enables cross-version development and management of apache flink and apache spark applications within a unified frame...",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L41",
          "evidence": "* Enables cross-version development and management of Apache Flink and Apache Spark applications within a unified framework."
        },
        {
          "url": "https://github.com/apache/streampark#L41",
          "evidence": "* Enables cross-version development and management of Apache Flink and Apache Spark applications within a unified framework."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "allowing even beginners to get started within minutes",
      "normalized_text": "Allowing even beginners to get started within minutes",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L47",
          "evidence": "* Only one service, deployment easy, allowing even beginners to get started within minutes."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run -d -p 10000:10000 apache/streampark:latest",
      "normalized_text": "Run -d -p 10000:10000 apache/streampark:latest",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L56",
          "evidence": "docker run -d -p 10000:10000 apache/streampark:latest"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide actual support services for this project",
      "normalized_text": "Provide actual support services for this project",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L99",
          "evidence": "> If you're new to posting issues, we ask that you read [*How To Ask Questions The Smart Way*](http://www.catb.org/~esr/faqs/smart-questions.html) (**This guide does not provide actual support services for this project!**), [How to Report Bugs Effectively](http://www.chiark.greenend.org.uk/~sgtatham/bugs.html) prior to posting. Well written bug reports help us help you!"
        },
        {
          "url": "https://github.com/apache/streampark#L99",
          "evidence": "> If you're new to posting issues, we ask that you read [*How To Ask Questions The Smart Way*](http://www.catb.org/~esr/faqs/smart-questions.html) (**This guide does not provide actual support services for this project!**), [How to Report Bugs Effectively](http://www.chiark.greenend.org.uk/~sgtatham/bugs.html) prior to posting. Well written bug reports help us help you!"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "*StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025.",
      "normalized_text": "*streampark** is an open-source streaming application development framework and cloud-native real-time computing plat...",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L32",
          "evidence": "**StreamPark** is an open-source streaming application development framework and cloud-native real-time computing platform. Designed to simplify the development and management of streaming applications, StreamPark provides a development framework for developing stream processing applications using Apache Flink and Apache Spark, alongside a professional management platform. The platform covers the full lifecycle of streaming applications, including development, debugging, interactive querying, deployment, operations, and maintenance. Originally named StreamX, the project was renamed as StreamPark in August 2022 and graduated as an Apache Top-Level Project (TLP) in January 2025."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* Only one service, deployment easy, allowing even beginners to get started within minutes.",
      "normalized_text": "* only one service, deployment easy, allowing even beginners to get started within minutes.",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/apache/streampark#L47",
          "evidence": "* Only one service, deployment easy, allowing even beginners to get started within minutes."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build workflow](https://github",
      "normalized_text": "Build workflow](https://github",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L3",
          "evidence": "[![Build Status](https://github.com/lakehq/sail/actions/workflows/build.yml/badge.svg?branch=main&event=push)](https://github.com/lakehq/sail/actions)"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L1",
          "evidence": "# firebolt ![Code Coverage Badge by Gopherbadger](coverage_badge.png)  ![Build Status](https://github.com/digitalocean/firebolt/actions/workflows/ci.yml/badge.svg) [![Go Report Card](https://goreportcard.com/badge/digitalocean/firebolt)](https://goreportcard.com/report/digitalocean/firebolt)"
        },
        {
          "url": "https://github.com/raystack/dagger#L3",
          "evidence": "![build workflow](https://github.com/raystack/dagger/actions/workflows/build.yml/badge.svg)"
        },
        {
          "url": "https://github.com/cross-platform/dspatch#L1",
          "evidence": "[![Build & Test](https://github.com/cross-platform/dspatch/actions/workflows/build_and_test.yml/badge.svg)](https://github.com/cross-platform/dspatch/actions/workflows/build_and_test.yml)"
        }
      ],
      "frequency": 4,
      "uniqueness_score": 0.25
    },
    {
      "text": "Compatible with the Spark Connect protocol, supporting the Spark SQL and DataFrame API with no code rewrites required.",
      "normalized_text": "Compatible with the spark connect protocol, supporting the spark sql and dataframe api with no code rewrites required.",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L12",
          "evidence": "- **Compatible** with the Spark Connect protocol, supporting the Spark SQL and DataFrame API with no code rewrites required."
        },
        {
          "url": "https://github.com/lakehq/sail#L12",
          "evidence": "- **Compatible** with the Spark Connect protocol, supporting the Spark SQL and DataFrame API with no code rewrites required."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "process step-by-step",
      "normalized_text": "Process step-by-step",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L39",
          "evidence": "You can install Sail from source to optimize performance for your specific hardware architecture. The detailed [Installation Guide](https://docs.lakesail.com/sail/latest/introduction/installation/) walks you through this process step-by-step."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides instructions for deploying sail on kubernetes clusters and other infrastructure configurations",
      "normalized_text": "Provides instructions for deploying sail on kubernetes clusters and other infrastructure configurations",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L41",
          "evidence": "If you need to deploy Sail in production environments, the [Deployment Guide](https://docs.lakesail.com/sail/latest/guide/deployment/) provides comprehensive instructions for deploying Sail on Kubernetes clusters and other infrastructure configurations."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "import sparkconnectserver",
      "normalized_text": "Import sparkconnectserver",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L56",
          "evidence": "from pysail.spark import SparkConnectServer"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run sail in cluster mode for distributed processing",
      "normalized_text": "Run sail in cluster mode for distributed processing",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L62",
          "evidence": "**Option 3: Kubernetes.** You can deploy Sail on Kubernetes and run Sail in cluster mode for distributed processing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "building the docker image and writing the kubernetes manifest yaml file",
      "normalized_text": "Building the docker image and writing the kubernetes manifest yaml file",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L63",
          "evidence": "Please refer to the [Kubernetes Deployment Guide](https://docs.lakesail.com/sail/latest/guide/deployment/kubernetes.html) for instructions on building the Docker image and writing the Kubernetes manifest YAML file."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "import sparksession",
      "normalized_text": "Import sparksession",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L76",
          "evidence": "from pyspark.sql import SparkSession"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports a variety of storage backends for reading and writing data",
      "normalized_text": "Supports a variety of storage backends for reading and writing data",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L88",
          "evidence": "Sail supports a variety of storage backends for reading and writing data. You can read more details in our [Storage Guide](https://docs.lakesail.com/sail/latest/guide/storage/)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "support for delta lake, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing delta datasets",
      "normalized_text": "Support for delta lake, offering a reliable storage layer with strong data management guarantees and ensuring interop...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L104",
          "evidence": "Sail provides native support for **Delta Lake**, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing Delta datasets."
        },
        {
          "url": "https://github.com/lakehq/sail#L104",
          "evidence": "Sail provides native support for **Delta Lake**, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing Delta datasets."
        },
        {
          "url": "https://github.com/lakehq/sail#L104",
          "evidence": "Sail provides native support for **Delta Lake**, offering a reliable storage layer with strong data management guarantees and ensuring interoperability with existing Delta datasets."
        }
      ],
      "frequency": 3,
      "uniqueness_score": 0.3333333333333333
    },
    {
      "text": "create a [pull request](https://github",
      "normalized_text": "Create a [pull request](https://github",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L135",
          "evidence": "Feel free to create a [pull request](https://github.com/lakehq/sail/pulls) if you would like to make a code change."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing and powered etl, machine learning, and analytics pipelines across industries",
      "normalized_text": "Processing and powered etl, machine learning, and analytics pipelines across industries",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L142",
          "evidence": "When Spark was invented over 15 years ago, it was revolutionary. It redefined distributed data processing and powered ETL, machine learning, and analytics pipelines across industries."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Row-based processing performs poorly on analytical workloads and leaves hardware efficiency untapped.",
      "normalized_text": "Row-based processing performs poorly on analytical workloads and leaves hardware efficiency untapped.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L149",
          "evidence": "- **Row-based processing** performs poorly on analytical workloads and leaves hardware efficiency untapped."
        },
        {
          "url": "https://github.com/lakehq/sail#L149",
          "evidence": "- **Row-based processing** performs poorly on analytical workloads and leaves hardware efficiency untapped."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "offers a drop-in replacement for spark sql and the spark dataframe api",
      "normalized_text": "Offers a drop-in replacement for spark sql and the spark dataframe api",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L156",
          "evidence": "Sail offers a drop-in replacement for Spark SQL and the Spark DataFrame API. Existing PySpark code works out of the box once you connect the Spark session to Sail over the Spark Connect protocol."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run on sail with identical semantics",
      "normalized_text": "Run on sail with identical semantics",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L159",
          "evidence": "- **DataFrame API Support.** Spark DataFrame operations run on Sail with identical semantics."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "enable zero-copy data sharing",
      "normalized_text": "Enable zero-copy data sharing",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L166",
          "evidence": "- **Lightning-Fast Python UDFs.** Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "runs inside sail with zero serialization overhead as arrow array pointers enable zero-copy data sharing",
      "normalized_text": "Runs inside sail with zero serialization overhead as arrow array pointers enable zero-copy data sharing",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L166",
          "evidence": "- **Lightning-Fast Python UDFs.** Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "handles execution for local and cluster modes",
      "normalized_text": "Handles execution for local and cluster modes",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L176",
          "evidence": "- [Query Planning](https://docs.lakesail.com/sail/latest/concepts/query-planning/) \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "builds logical and physical plans, and handles execution for local and cluster modes",
      "normalized_text": "Builds logical and physical plans, and handles execution for local and cluster modes",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L176",
          "evidence": "- [Query Planning](https://docs.lakesail.com/sail/latest/concepts/query-planning/) \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "100% Rust-native with no JVM overhead, delivering memory safety, instant startup, and predictable performance.",
      "normalized_text": "100% rust-native with no jvm overhead, delivering memory safety, instant startup, and predictable performance.",
      "category": "Security & Privacy",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L15",
          "evidence": "- **100% Rust-native** with no JVM overhead, delivering memory safety, instant startup, and predictable performance."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "*Option 3: Kubernetes.** You can deploy Sail on Kubernetes and run Sail in cluster mode for distributed processing.",
      "normalized_text": "*option 3: kubernetes.** you can deploy sail on kubernetes and run sail in cluster mode for distributed processing.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L62",
          "evidence": "**Option 3: Kubernetes.** You can deploy Sail on Kubernetes and run Sail in cluster mode for distributed processing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Spark SQL Dialect Support. A custom Rust parser (built with parser combinators and Rust procedural macros) covers Spark SQL syntax with production-grade accuracy.",
      "normalized_text": "Spark sql dialect support. a custom rust parser (built with parser combinators and rust procedural macros) covers spa...",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L158",
          "evidence": "- **Spark SQL Dialect Support.** A custom Rust parser (built with parser combinators and Rust procedural macros) covers Spark SQL syntax with production-grade accuracy."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "DataFrame API Support. Spark DataFrame operations run on Sail with identical semantics.",
      "normalized_text": "Dataframe api support. spark dataframe operations run on sail with identical semantics.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L159",
          "evidence": "- **DataFrame API Support.** Spark DataFrame operations run on Sail with identical semantics."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Python UDF, UDAF, UDWF, and UDTF Support. Python, Pandas, and Arrow UDFs all follow the same conventions as Spark.",
      "normalized_text": "Python udf, udaf, udwf, and udtf support. python, pandas, and arrow udfs all follow the same conventions as spark.",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L160",
          "evidence": "- **Python UDF, UDAF, UDWF, and UDTF Support.** Python, Pandas, and Arrow UDFs all follow the same conventions as Spark."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Lightning-Fast Python UDFs. Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing.",
      "normalized_text": "Lightning-fast python udfs. python code runs inside sail with zero serialization overhead as arrow array pointers ena...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L166",
          "evidence": "- **Lightning-Fast Python UDFs.** Python code runs inside Sail with zero serialization overhead as Arrow array pointers enable zero-copy data sharing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Performant Data Shuffling. Workers exchange Arrow columnar data directly, minimizing shuffle costs for joins and aggregations.",
      "normalized_text": "Performant data shuffling. workers exchange arrow columnar data directly, minimizing shuffle costs for joins and aggr...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L167",
          "evidence": "- **Performant Data Shuffling.** Workers exchange Arrow columnar data directly, minimizing shuffle costs for joins and aggregations."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Query Planning \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes.",
      "normalized_text": "Query planning \u2013 detailed explanation of how sail parses sql and spark relations, builds logical and physical plans, ...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/lakehq/sail#L176",
          "evidence": "- [Query Planning](https://docs.lakesail.com/sail/latest/concepts/query-planning/) \u2013 Detailed explanation of how Sail parses SQL and Spark relations, builds logical and physical plans, and handles execution for local and cluster modes."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing framework with strong gpu acceleration",
      "normalized_text": "Processing framework with strong gpu acceleration",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L1",
          "evidence": "# BMF - Cross-platform, multi-language, customizable video processing framework with strong GPU acceleration"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing framework developed by [bytedance](https://www",
      "normalized_text": "Processing framework developed by [bytedance](https://www",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L3",
          "evidence": "**BMF (Babit Multimedia Framework)** is a cross-platform, multi-language, customizable multimedia processing framework developed by [**ByteDance**](https://www.bytedance.com/en)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing scenarios",
      "normalized_text": "Processing scenarios",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L4",
          "evidence": "With over 4 years of testing and improvements, BMF has been tailored to adeptly tackle challenges in our real-world production environments. It is currently widely used in ByteDance's video streaming, live transcoding, cloud editing and mobile pre/post processing scenarios. More than 2 billion videos are processed by the framework every day."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Easy to use: BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages.",
      "normalized_text": "Easy to use: bmf provides python, go, and c++ apis, allowing developers the flexibility to code in their favourite la...",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L10",
          "evidence": "- **Easy to use:** BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages."
        },
        {
          "url": "https://github.com/BabitMF/bmf#L10",
          "evidence": "- **Easy to use:** BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages."
        },
        {
          "url": "https://github.com/BabitMF/bmf#L10",
          "evidence": "- **Easy to use:** BMF provides Python, Go, and C++ APIs, allowing developers the flexibility to code in their favourite languages."
        }
      ],
      "frequency": 3,
      "uniqueness_score": 0.3333333333333333
    },
    {
      "text": "support for heterogeneous acceleration hardware",
      "normalized_text": "Support for heterogeneous acceleration hardware",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L14",
          "evidence": "- **High performance:** BMF has a powerful scheduler and strong support for heterogeneous acceleration hardware. Moreover, [**NVIDIA**](https://www.nvidia.com/) has been cooperating with us to develop a highly optimized GPU pipeline for video transcoding and AI inference."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "offers seamless data format conversions across popular frameworks (ffmpeg/numpy/pytorch/opencv/tensorrt), conversion between hardware devices (cpu/gpu), and color space and pixel format conversion",
      "normalized_text": "Offers seamless data format conversions across popular frameworks (ffmpeg/numpy/pytorch/opencv/tensorrt), conversion ...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L16",
          "evidence": "- **Efficient data conversion:** BMF offers seamless data format conversions across popular frameworks (FFmpeg/Numpy/PyTorch/OpenCV/TensorRT), conversion between hardware devices (CPU/GPU), and color space and pixel format conversion."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing framework",
      "normalized_text": "Processing framework",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L19",
          "evidence": "[**BMFLite**](./bmf_lite/README.md) is a client-side cross-platform, lightweight, more efficient client-side multimedia processing framework."
        },
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L8",
          "evidence": "High performance Stream Processing Framework. A new, faster, implementation of Apache Flink from scratch in Rust."
        },
        {
          "url": "https://github.com/cdapio/tigon#L7",
          "evidence": "**Tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework."
        }
      ],
      "frequency": 3,
      "uniqueness_score": 0.3333333333333333
    },
    {
      "text": "processing videos and pictures trillions of times every day",
      "normalized_text": "Processing videos and pictures trillions of times every day",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L20",
          "evidence": "So far, the BMFLite client-side algorithm is used in apps such as Douyin/Xigua, serving more than one billion users in live streaming/video playing/pictures/cloud games and other scenarios, and processing videos and pictures trillions of times every day."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allowing you to experience them intuitively",
      "normalized_text": "Allowing you to experience them intuitively",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L25",
          "evidence": "In this section, we will directly showcase the capabilities of the BMF framework around six dimensions: **Transcode**, **Edit**, **Meeting/Broadcaster**, **GPU acceleration**, **AI Inference**, and **client-side Framework**. For all the demos provided below, corresponding implementations and documentation are available on Google Colab, allowing you to experience them intuitively."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "implement a high-complexity audio and video editing pipeline through the bmf framework",
      "normalized_text": "Implement a high-complexity audio and video editing pipeline through the bmf framework",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L33",
          "evidence": "The Edit Demo will show you how to implement a high-complexity audio and video editing pipeline through the BMF framework. We have implemented two Python modules, video_concat and video_overlay, and combined various atomic capabilities to construct a complex BMF Graph."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an rtmp server",
      "normalized_text": "Enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an r...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L38",
          "evidence": "This demo uses BMF framework to construct a simple broadcast service. The service provides an API that enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an RTMP server. This demo showcases the modularity of BMF, multi-language development, and the ability to dynamically adjust the pipeline."
        },
        {
          "url": "https://github.com/BabitMF/bmf#L38",
          "evidence": "This demo uses BMF framework to construct a simple broadcast service. The service provides an API that enables dynamic video source pulling, video layout control, audio mixing, and ultimately streaming the output to an RTMP server. This demo showcases the modularity of BMF, multi-language development, and the ability to dynamically adjust the pipeline."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "* Ability to extend , there are new C++, Python modules added",
      "normalized_text": "* ability to extend , there are new c++, python modules added",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L52",
          "evidence": "*   Ability to extend easily, there are new C++, Python modules added simply"
        },
        {
          "url": "https://github.com/BabitMF/bmf#L52",
          "evidence": "*   Ability to extend easily, there are new C++, Python modules added simply"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "process between cpu and gpu",
      "normalized_text": "Process between cpu and gpu",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L57",
          "evidence": "*   Heterogeneous pipeline is supported in BMF, such as process between CPU and GPU"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "builds a transcoding pipeline which fully runs on gpu:",
      "normalized_text": "Builds a transcoding pipeline which fully runs on gpu:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L68",
          "evidence": "The demo builds a transcoding pipeline which fully runs on GPU:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing each day",
      "normalized_text": "Processing each day",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L79",
          "evidence": "The [prototype]() of how to build a video preprocessing for LLM training data in Bytedance, which serves billions of clip processing each day."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build a video preprocessing for llm training data in bytedance, which serves billions of clip processing each day",
      "normalized_text": "Build a video preprocessing for llm training data in bytedance, which serves billions of clip processing each day",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L79",
          "evidence": "The [prototype]() of how to build a video preprocessing for LLM training data in Bytedance, which serves billions of clip processing each day."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "integrate the state of art ai algorithms into the bmf video processing pipeline",
      "normalized_text": "Integrate the state of art ai algorithms into the bmf video processing pipeline",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L88",
          "evidence": "This demo shows how to integrate the state of art AI algorithms into the BMF video processing pipeline. The famous open source colorization algorithm [DeOldify](https://github.com/jantic/DeOldify) is wrapped as a BMF pyhton module in less than 100 lines of codes. The final effect is illustrated below, with the original video on the left side and the colored video on the right."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing & data pipeline apps",
      "normalized_text": "Processing & data pipeline apps",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L88",
          "evidence": "This demo shows how to integrate the state of art AI algorithms into the BMF video processing pipeline. The famous open source colorization algorithm [DeOldify](https://github.com/jantic/DeOldify) is wrapped as a BMF pyhton module in less than 100 lines of codes. The final effect is illustrated below, with the original video on the left side and the colored video on the right."
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L4",
          "evidence": "A golang framework for streaming event processing & data pipeline apps"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L48",
          "evidence": "or sorting that require shuffling data within the cluster.   Firebolt is for 'straight through' processing pipelines that are"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L12",
          "evidence": "* event processing pipelines"
        },
        {
          "url": "https://github.com/cdapio/tigon#L113",
          "evidence": "Demonstrates using TigonSQL to write a webpage click stream data processing application."
        }
      ],
      "frequency": 5,
      "uniqueness_score": 0.2
    },
    {
      "text": "implements the super-resolution inference process of [real-esrgan](https://github",
      "normalized_text": "Implements the super-resolution inference process of [real-esrgan](https://github",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L95",
          "evidence": "This demo implements the super-resolution inference process of [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) as a BMF module, showcasing a BMF pipeline that combines decoding, super-resolution inference and encoding."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process of [real-esrgan](https://github",
      "normalized_text": "Process of [real-esrgan](https://github",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L95",
          "evidence": "This demo implements the super-resolution inference process of [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) as a BMF module, showcasing a BMF pipeline that combines decoding, super-resolution inference and encoding."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process the input video",
      "normalized_text": "Process the input video",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L108",
          "evidence": "This Demo shows a full-link face detect pipeline based on TensorRT acceleration, which internally uses the TensorRT-accelerated Onnx model to process the input video. It uses the NMS algorithm to filter repeated candidate boxes to form an output, which can be used to process a Face Detection Task efficiently."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process a face detection task efficiently",
      "normalized_text": "Process a face detection task efficiently",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L108",
          "evidence": "This Demo shows a full-link face detect pipeline based on TensorRT acceleration, which internally uses the TensorRT-accelerated Onnx model to process the input video. It uses the NMS algorithm to filter repeated candidate boxes to form an output, which can be used to process a Face Detection Task efficiently."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "implements the denoise algorithm as a bmf module, showcasing a bmf pipeline that combines video capture, noise reduction and rendering",
      "normalized_text": "Implements the denoise algorithm as a bmf module, showcasing a bmf pipeline that combines video capture, noise reduct...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L120",
          "evidence": "This example implements the denoise algorithm as a BMF module, showcasing a BMF pipeline that combines video capture, noise reduction and rendering."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a module](https://babitmf",
      "normalized_text": "Create a module](https://babitmf",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L143",
          "evidence": "- [Create a Graph](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_graph/)"
        },
        {
          "url": "https://github.com/BabitMF/bmf#L151",
          "evidence": "- [Create a Module](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_module/)"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "customize module with python, c++ and go",
      "normalized_text": "Customize module with python, c++ and go",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L152",
          "evidence": "- customize module with python, C++ and Go. You can try it on [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BabitMF/bmf/blob/master/bmf/test/customize_module/bmf_customize_demo_latest.ipynb)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "track and resolve problems",
      "normalized_text": "Track and resolve problems",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L186",
          "evidence": "We use GitHub issues to track and resolve problems. If you have any questions, please feel free to join the discussion and work with us to find a solution."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "*BMF (Babit Multimedia Framework) is a cross-platform, multi-language, customizable multimedia processing framework developed by ByteDance**.",
      "normalized_text": "*bmf (babit multimedia framework) is a cross-platform, multi-language, customizable multimedia processing framework d...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L3",
          "evidence": "**BMF (Babit Multimedia Framework)** is a cross-platform, multi-language, customizable multimedia processing framework developed by [**ByteDance**](https://www.bytedance.com/en)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Cross-Platform Support: Native compatibility with Linux, Windows, and macOS, as well as optimization for both x86 and ARM CPUs.",
      "normalized_text": "Cross-platform support: native compatibility with linux, windows, and macos, as well as optimization for both x86 and...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L8",
          "evidence": "- **Cross-Platform Support:** Native compatibility with Linux, Windows, and macOS, as well as optimization for both x86 and ARM CPUs."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "High performance: BMF has a scheduler and strong support for heterogeneous acceleration hardware. Moreover, NVIDIA has been cooperating with us to develop a highly optimized GPU pipeline for video transcoding and AI inference.",
      "normalized_text": "High performance: bmf has a scheduler and strong support for heterogeneous acceleration hardware. moreover, nvidia ha...",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L14",
          "evidence": "- **High performance:** BMF has a powerful scheduler and strong support for heterogeneous acceleration hardware. Moreover, [**NVIDIA**](https://www.nvidia.com/) has been cooperating with us to develop a highly optimized GPU pipeline for video transcoding and AI inference."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Efficient data conversion: BMF offers seamless data format conversions across popular frameworks (FFmpeg/Numpy/PyTorch/OpenCV/TensorRT), conversion between hardware devices (CPU/GPU), and color space and pixel format conversion.",
      "normalized_text": "Efficient data conversion: bmf offers seamless data format conversions across popular frameworks (ffmpeg/numpy/pytorc...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L16",
          "evidence": "- **Efficient data conversion:** BMF offers seamless data format conversions across popular frameworks (FFmpeg/Numpy/PyTorch/OpenCV/TensorRT), conversion between hardware devices (CPU/GPU), and color space and pixel format conversion."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* Heterogeneous pipeline is supported in BMF, such as process between CPU and GPU",
      "normalized_text": "* heterogeneous pipeline is supported in bmf, such as process between cpu and gpu",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L57",
          "evidence": "*   Heterogeneous pipeline is supported in BMF, such as process between CPU and GPU"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- Create a Graph",
      "normalized_text": "- create a graph",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L143",
          "evidence": "- [Create a Graph](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_graph/)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- Create a Module",
      "normalized_text": "- create a module",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L151",
          "evidence": "- [Create a Module](https://babitmf.github.io/docs/bmf/getting_started_yourself/create_a_module/)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- customize module with python, C++ and Go. You can try it on [Open In Colab](https://colab.research.google.com/github/BabitMF/bmf/blob/master/bmf/test/customize_module/bmf_customize_demo_latest.ipynb)",
      "normalized_text": "- customize module with python, c++ and go. you can try it on [open in colab](https://colab.research.google.com/githu...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/BabitMF/bmf#L152",
          "evidence": "- customize module with python, C++ and Go. You can try it on [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BabitMF/bmf/blob/master/bmf/test/customize_module/bmf_customize_demo_latest.ipynb)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process a stream of data",
      "normalized_text": "Process a stream of data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L7",
          "evidence": "Firebolt has a simple model intended to make it easier to write reliable pipeline applications that process a stream of data."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build systems such as:",
      "normalized_text": "Build systems such as:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L9",
          "evidence": "It can be used to build systems such as:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "implement the `node",
      "normalized_text": "Implement the `node",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L15",
          "evidence": "must implement the `node.Source` interface."
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L24",
          "evidence": "cases.  Each node must implement the `node.SyncNode`, `node.FanoutNode`, or `node.AsyncNode` interfaces accordingly."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "provide one built-in source:",
      "normalized_text": "Provide one built-in source:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L17",
          "evidence": "We provide one built-in source:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing of your application is executed by its nodes which form a processing tree",
      "normalized_text": "Processing of your application is executed by its nodes which form a processing tree",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L21",
          "evidence": "The processing of your application is executed by its **nodes** which form a processing tree.  Data - events - flow down"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process events synchronously or",
      "normalized_text": "Process events synchronously or",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L22",
          "evidence": "this tree.   A parent **node** passes results down to it's child **nodes**.  Nodes may process events synchronously or"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide two built-in node types:",
      "normalized_text": "Provide two built-in node types:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L26",
          "evidence": "We provide two built-in node types:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run and compile-time dependencies on `librdkafka`, see developing",
      "normalized_text": "Run and compile-time dependencies on `librdkafka`, see developing",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L31",
          "evidence": "Firebolt has both run and compile-time dependencies on `librdkafka`, see [Developing](#developing)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "handle large data volume",
      "normalized_text": "Handle large data volume",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L45",
          "evidence": "to run a clustered application that scales predictably to handle large data volume."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run a clustered application that scales predictably to handle large data volume",
      "normalized_text": "Run a clustered application that scales predictably to handle large data volume",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L45",
          "evidence": "to run a clustered application that scales predictably to handle large data volume."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide an easy way to support 'wide operations' like record grouping, windowing,",
      "normalized_text": "Provide an easy way to support 'wide operations' like record grouping, windowing,",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L47",
          "evidence": "It is not an analytics tool - it does not provide an easy way to support 'wide operations' like record grouping, windowing,"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L47",
          "evidence": "It is not an analytics tool - it does not provide an easy way to support 'wide operations' like record grouping, windowing,"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "processing to a kafka topic for recovery or analysis with a few lines of config",
      "normalized_text": "Processing to a kafka topic for recovery or analysis with a few lines of config",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L56",
          "evidence": "* **convenient error handling** Send events that fail processing to a kafka topic for recovery or analysis with a few lines of config"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window",
      "normalized_text": "Process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L58",
          "evidence": "* **outage recovery: parallel recovery** After an outage, process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "track the performance of your source and all nodes without writing code",
      "normalized_text": "Track the performance of your source and all nodes without writing code",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L59",
          "evidence": "* **monitorability** Firebolt exposes Prometheus metrics to track the performance of your Source and all Nodes without writing code.  Your nodes can expose their own custom internal metrics as needed."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing that may need to be conducted on one-and-only-one instance",
      "normalized_text": "Processing that may need to be conducted on one-and-only-one instance",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L60",
          "evidence": "* **leader election** Firebolt uses Zookeeper to conduct leader elections, facilitating any processing that may need to be conducted on one-and-only-one instance."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "implementing and using asynchronous nodes",
      "normalized_text": "Implementing and using asynchronous nodes",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L73",
          "evidence": "5. [Sources ](docs/sources.md) Implementing and using sources"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L75",
          "evidence": "6. [Sync Nodes ](docs/sync-nodes.md) Implementing and using synchronous nodes"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L77",
          "evidence": "7. [Fanout Nodes ](docs/fanout-nodes.md) Implementing and using fanout nodes"
        },
        {
          "url": "https://github.com/digitalocean/firebolt#L79",
          "evidence": "8. [Async Nodes ](docs/async-nodes.md) Implementing and using asynchronous nodes"
        }
      ],
      "frequency": 4,
      "uniqueness_score": 0.25
    },
    {
      "text": "* kafka sources Minimal configuration and no code required to consume from a Kafka topic, consumer lag metrics included",
      "normalized_text": "* kafka sources minimal configuration and no code required to consume from a kafka topic, consumer lag metrics included",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L52",
          "evidence": "* **kafka sources** Minimal configuration and no code required to consume from a Kafka topic, consumer lag metrics included"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* convenient error handling Send events that fail processing to a kafka topic for recovery or analysis with a few lines of config",
      "normalized_text": "* convenient error handling send events that fail processing to a kafka topic for recovery or analysis with a few lin...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L56",
          "evidence": "* **convenient error handling** Send events that fail processing to a kafka topic for recovery or analysis with a few lines of config"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* outage recovery: offset management Configurable Kafka offset management during recovery lets you determine the maximum \"catch up\" to attempt after an outage, so you can get back to realtime processing.",
      "normalized_text": "* outage recovery: offset management configurable kafka offset management during recovery lets you determine the maxi...",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L57",
          "evidence": "* **outage recovery: offset management** Configurable Kafka offset management during recovery lets you determine the maximum \"catch up\" to attempt after an outage, so you can quickly get back to realtime processing."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* outage recovery: parallel recovery After an outage, process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window.",
      "normalized_text": "* outage recovery: parallel recovery after an outage, process realtime data and \"fill-in\" the outage time window in p...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L58",
          "evidence": "* **outage recovery: parallel recovery** After an outage, process realtime data and \"fill-in\" the outage time window in parallel, with a rate limit on the recovery window."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* monitorability Firebolt exposes Prometheus metrics to track the performance of your Source and all Nodes without writing code. Your nodes can expose their own custom internal metrics as needed.",
      "normalized_text": "* monitorability firebolt exposes prometheus metrics to track the performance of your source and all nodes without wr...",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L59",
          "evidence": "* **monitorability** Firebolt exposes Prometheus metrics to track the performance of your Source and all Nodes without writing code.  Your nodes can expose their own custom internal metrics as needed."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "* leader election Firebolt uses Zookeeper to conduct leader elections, facilitating any processing that may need to be conducted on one-and-only-one instance.",
      "normalized_text": "* leader election firebolt uses zookeeper to conduct leader elections, facilitating any processing that may need to b...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/digitalocean/firebolt#L60",
          "evidence": "* **leader election** Firebolt uses Zookeeper to conduct leader elections, facilitating any processing that may need to be conducted on one-and-only-one instance."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "runs as a plugin, aiming to encapsulate various existing libraries to simplify the development of plugins",
      "normalized_text": "Runs as a plugin, aiming to encapsulate various existing libraries to simplify the development of plugins",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L10",
          "evidence": "<p>Based on <a href=\"https://github.com/FairyProject/fairy\" target=\"_blank\">Fairy Framework</a>, it runs as a plugin, aiming to encapsulate various existing libraries to simplify the development of plugins.</p>"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "plugin toolkit built on [fairy framework](https://github",
      "normalized_text": "Plugin toolkit built on [fairy framework](https://github",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L15",
          "evidence": "A Modular Plugin Toolkit built on [Fairy Framework](https://github.com/FairyProject/fairy), featuring modular design and"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides essential tools and utilities for modern minecraft plugin development with cross-platform support for",
      "normalized_text": "Provides essential tools and utilities for modern minecraft plugin development with cross-platform support for",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L17",
          "evidence": "It provides essential tools and utilities for modern Minecraft plugin development with cross-platform support for"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "plugin development with cross-platform support for",
      "normalized_text": "Plugin development with cross-platform support for",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L17",
          "evidence": "It provides essential tools and utilities for modern Minecraft plugin development with cross-platform support for"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "annotation - annotation processing framework with scanning options and",
      "normalized_text": "Annotation - annotation processing framework with scanning options and",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L24",
          "evidence": "- [**annotation**](annotation/README.md) - Powerful annotation processing framework with flexible scanning options and"
        },
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L24",
          "evidence": "- [**annotation**](annotation/README.md) - Powerful annotation processing framework with flexible scanning options and"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "building high-performance",
      "normalized_text": "Building high-performance",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L35",
          "evidence": "- [**player**](player/README.md) - Enterprise-grade distributed data management framework building high-performance"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports `rhino`, `nashorn` and `v8` `javascript` engines",
      "normalized_text": "Supports `rhino`, `nashorn` and `v8` `javascript` engines",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L39",
          "evidence": "that supports `Rhino`, `Nashorn` and `V8` `JavaScript` engines."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "plugin decoupling and",
      "normalized_text": "Plugin decoupling and",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L44",
          "evidence": "via gRPC external task schedulers (currently implemented in Rust), enabling large plugin decoupling and"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "plugin development project, and will release the",
      "normalized_text": "Plugin development project, and will release the",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L55",
          "evidence": "In fact, we plan to extensively utilize this version in a large-scale plugin development project, and will release the"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "plugin for direct server use",
      "normalized_text": "Plugin for direct server use",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L63",
          "evidence": "- `-plugin`: Compiled plugin for direct server use"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "configure github authentication",
      "normalized_text": "Configure github authentication",
      "category": "Security & Privacy",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L70",
          "evidence": "Configure GitHub authentication"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "commons - Essential utilities including VarHandle injection, task scheduling, virtual thread",
      "normalized_text": "Commons - essential utilities including varhandle injection, task scheduling, virtual thread",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L28",
          "evidence": "- [**commons**](commons/README.md) - Essential utilities including VarHandle injection, task scheduling, virtual thread"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "player - Enterprise-grade distributed data management framework building high-performance",
      "normalized_text": "Player - enterprise-grade distributed data management framework building high-performance",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L35",
          "evidence": "- [**player**](player/README.md) - Enterprise-grade distributed data management framework building high-performance"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "script - , , extensible, and high-performance script execution engine wrapper",
      "normalized_text": "Script - , , extensible, and high-performance script execution engine wrapper",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L38",
          "evidence": "- [**script**](script/README.md) - Powerful, flexible, extensible, and high-performance script execution engine wrapper"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "experimental - Some experimental modules that can significantly improve performance, but",
      "normalized_text": "Experimental - some experimental modules that can significantly improve performance, but",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L41",
          "evidence": "- [**experimental**](experimental/README.md) - Some experimental modules that can significantly improve performance, but"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- third-party-schedulers - Achieves distributed task processing",
      "normalized_text": "- third-party-schedulers - achieves distributed task processing",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L43",
          "evidence": "- [**third-party-schedulers**](experimental/third-party-schedulers/README.md) - Achieves distributed task processing"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "`-javadoc`: Generated API documentation",
      "normalized_text": "`-javadoc`: generated api documentation",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L62",
          "evidence": "- `-javadoc`: Generated API documentation"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "`-plugin`: Compiled plugin for direct server use",
      "normalized_text": "`-plugin`: compiled plugin for direct server use",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/LegacyLands/legacy-lands-library#L63",
          "evidence": "- `-plugin`: Compiled plugin for direct server use"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build --release --color=always --all --all-targets",
      "normalized_text": "Build --release --color=always --all --all-targets",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L79",
          "evidence": "cargo build --color=always --all --all-targets"
        },
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L81",
          "evidence": "cargo build --release --color=always --all --all-targets"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "build image example-simple",
      "normalized_text": "Build image example-simple",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L212",
          "evidence": "### Build image example-simple"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build -t xxx:xx -f",
      "normalized_text": "Build -t xxx:xx -f",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L215",
          "evidence": "sudo docker build -t xxx:xx -f ./docker/Dockerfile_example_simple ."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "-F \"file=@/path/to/execute_file\" \\",
      "normalized_text": "-f \"file=@/path/to/execute_file\" \\",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L132",
          "evidence": "-F \"file=@/path/to/execute_file\" \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "-d '{\"batch_args\":[{\"cluster_mode\":\"Standalone\", \"manager_type\":\"Coordinator\",\"num_task_managers\":\"15\"}]}' \\",
      "normalized_text": "-d '{\"batch_args\":[{\"cluster_mode\":\"standalone\", \"manager_type\":\"coordinator\",\"num_task_managers\":\"15\"}]}' \\",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L139",
          "evidence": "-d '{\"batch_args\":[{\"cluster_mode\":\"Standalone\", \"manager_type\":\"Coordinator\",\"num_task_managers\":\"15\"}]}' \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "--worker_process_path hdfs://nn/path/to/rlink-showcase \\",
      "normalized_text": "--worker_process_path hdfs://nn/path/to/rlink-showcase \\",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L171",
          "evidence": "--worker_process_path hdfs://nn/path/to/rlink-showcase \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "--java_manager_path hdfs://nn/path/to/rlink-yarn-manager-{version}-jar-with-dependencies.jar \\",
      "normalized_text": "--java_manager_path hdfs://nn/path/to/rlink-yarn-manager-{version}-jar-with-dependencies.jar \\",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L172",
          "evidence": "--java_manager_path hdfs://nn/path/to/rlink-yarn-manager-{version}-jar-with-dependencies.jar \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "--yarn_manager_main_class rlink.yarn.manager.ResourceManagerCli \\",
      "normalized_text": "--yarn_manager_main_class rlink.yarn.manager.resourcemanagercli \\",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L173",
          "evidence": "--yarn_manager_main_class rlink.yarn.manager.ResourceManagerCli \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "--manager_type Coordinator \\",
      "normalized_text": "--manager_type coordinator \\",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L181",
          "evidence": "--manager_type Coordinator \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "--num_task_managers 80 \\",
      "normalized_text": "--num_task_managers 80 \\",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L182",
          "evidence": "--num_task_managers 80 \\"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "--application_process_arg xxx",
      "normalized_text": "--application_process_arg xxx",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L183",
          "evidence": "--application_process_arg xxx"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "KubeConfig, configurable via ~/.kube/config. You can verify permissions by running kubectl auth can-i <list|create|edit|delete> pods",
      "normalized_text": "Kubeconfig, configurable via ~/.kube/config. you can verify permissions by running kubectl auth can-i <list|create|ed...",
      "category": "Security & Privacy",
      "sources": [
        {
          "url": "https://github.com/rlink-rs/rlink-rs#L191",
          "evidence": "- KubeConfig, configurable via ~/.kube/config. You can verify permissions by running kubectl auth can-i <list|create|edit|delete> pods"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build status\" />",
      "normalized_text": "Build status\" />",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L9",
          "evidence": "<img src=\"https://travis-ci.com/gojek/ziggurat.svg?branch=master\" alt=\"Build Status\" />"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing on kafka",
      "normalized_text": "Processing on kafka",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L34",
          "evidence": "Ziggurat is a framework built to simplify stream processing on Kafka. It can be used to create a full-fledged Clojure app that reads and processes messages from Kafka. Ziggurat abstracts the following features:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a -fledged clojure app that reads and processes messages from kafka",
      "normalized_text": "Create a -fledged clojure app that reads and processes messages from kafka",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L34",
          "evidence": "Ziggurat is a framework built to simplify stream processing on Kafka. It can be used to create a full-fledged Clojure app that reads and processes messages from Kafka. Ziggurat abstracts the following features:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run docker-compose: `docker-compose up`",
      "normalized_text": "Run docker-compose: `docker-compose up`",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L58",
          "evidence": "3. Run docker-compose: `docker-compose up`. This starts:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run tests: `make test`",
      "normalized_text": "Run tests: `make test`",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L62",
          "evidence": "4. Run tests: `make test`"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run `make setup-cluster`",
      "normalized_text": "Run `make setup-cluster`",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L66",
          "evidence": "- Run `make setup-cluster`. This clears up the volume and starts:"
        },
        {
          "url": "https://github.com/gojek/ziggurat#L73",
          "evidence": "- Run `make test-cluster`. This uses `config.test.cluster.edn` instead of `config.test.edn`."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "runs at shutdown goes here",
      "normalized_text": "Runs at shutdown goes here",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L91",
          "evidence": ";; your logic that runs at startup goes here"
        },
        {
          "url": "https://github.com/gojek/ziggurat#L95",
          "evidence": ";; your logic that runs at shutdown goes here"
        },
        {
          "url": "https://github.com/gojek/ziggurat#L146",
          "evidence": ";; your logic that runs at startup goes here"
        },
        {
          "url": "https://github.com/gojek/ziggurat#L150",
          "evidence": ";; your logic that runs at shutdown goes here"
        }
      ],
      "frequency": 4,
      "uniqueness_score": 0.25
    },
    {
      "text": "track skipped messages",
      "normalized_text": "Track skipped messages",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L127",
          "evidence": "- :skip - The message should be skipped without reporting its failure or retrying the message. Same as :success except that a different metric is published to track skipped messages"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc.",
      "normalized_text": "The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, t...",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L128",
          "evidence": "- The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc."
        },
        {
          "url": "https://github.com/gojek/ziggurat#L128",
          "evidence": "- The start-fn is run at the application startup and can be used to initialize connection to databases, http clients, thread-pools, etc."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc",
      "normalized_text": "Run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc",
      "category": "Documentation",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L129",
          "evidence": "- The stop-fn is run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc."
        },
        {
          "url": "https://github.com/gojek/ziggurat#L129",
          "evidence": "- The stop-fn is run at shutdown and facilitates graceful shutdown, for example, releasing db connections, shutting down http servers etc."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is a unique identifier per stream which needs to be included in config.edn file",
      "normalized_text": "Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L134",
          "evidence": "- Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is a unique identifier per stream which needs to be included in config.edn file"
        },
        {
          "url": "https://github.com/gojek/ziggurat#L134",
          "evidence": "- Ziggurat enables reading from multiple streams and applying same/different functions to the messages. `:stream-id` is a unique identifier per stream which needs to be included in config.edn file"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Toggle Streams on a Running Actor",
      "normalized_text": "Toggle streams on a running actor",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L45",
          "evidence": "- [Toggle Streams on a Running Actor](doc/CONCEPTS.md#toggle-streams-in-running-actor)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Run `make setup-cluster`. This clears up the volume and starts:",
      "normalized_text": "Run `make setup-cluster`. this clears up the volume and starts:",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L66",
          "evidence": "- Run `make setup-cluster`. This clears up the volume and starts:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Run `make test-cluster`. This uses `config.test.cluster.edn` instead of `config.test.edn`.",
      "normalized_text": "Run `make test-cluster`. this uses `config.test.cluster.edn` instead of `config.test.edn`.",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L73",
          "evidence": "- Run `make test-cluster`. This uses `config.test.cluster.edn` instead of `config.test.edn`."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- :success - The message was successfully processed and the stream should continue to the next message",
      "normalized_text": "- :success - the message was successfully processed and the stream should continue to the next message",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L124",
          "evidence": "- :success - The message was successfully processed and the stream should continue to the next message"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- :retry - The message failed to be processed and it should be retried via RabbitMQ.",
      "normalized_text": "- :retry - the message failed to be processed and it should be retried via rabbitmq.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L125",
          "evidence": "- :retry - The message failed to be processed and it should be retried via RabbitMQ."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "- :skip - The message should be skipped without reporting its failure or retrying the message. Same as :success except that a different metric is published to track skipped messages",
      "normalized_text": "- :skip - the message should be skipped without reporting its failure or retrying the message. same as :success excep...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/gojek/ziggurat#L127",
          "evidence": "- :skip - The message should be skipped without reporting its failure or retrying the message. Same as :success except that a different metric is published to track skipped messages"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process while performing various activities or tasks",
      "normalized_text": "Process while performing various activities or tasks",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L13",
          "evidence": "A Streaming Computation Framework Based on Golang. Emphasizes maintaining a simple, clear, and smooth process while performing various activities or tasks."
        },
        {
          "url": "https://github.com/aceld/kis-flow#L13",
          "evidence": "A Streaming Computation Framework Based on Golang. Emphasizes maintaining a simple, clear, and smooth process while performing various activities or tasks."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "supports a passive consumption mode, providing kisflow with real-time computing capabilities",
      "normalized_text": "Supports a passive consumption mode, providing kisflow with real-time computing capabilities",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports operator expression splicing, connector integration, strategy configuration, stateful function mode, and slink stream splicing",
      "normalized_text": "Supports operator expression splicing, connector integration, strategy configuration, stateful function mode, and sli...",
      "category": "Integration & APIs",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing policies for kisfunctions, allowing functions to have fixed independent processing capabilities",
      "normalized_text": "Processing policies for kisfunctions, allowing functions to have fixed independent processing capabilities",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        },
        {
          "url": "https://github.com/aceld/kis-flow#L56",
          "evidence": "| Flowing Computation Layer | The upstream computing layer for KisFlow, which directly connects to business storage and the ODS (Operational Data Store) layer of data warehouses. The upstream can be MySQL Binlog, logs, interface data, etc., and it supports a passive consumption mode, providing KisFlow with real-time computing capabilities. | **KisFlow**: Distributed batch consumer; a KisFlow is composed of multiple KisFunctions. <br /><br />**KisConnectors**: Computing data stream intermediate state persistence and connectors. <br /><br />**KisFunctions**: Supports operator expression splicing, connector integration, strategy configuration, Stateful Function mode, and Slink stream splicing. <br /><br />**KisConfig**: Binding of flow processing policies for KisFunctions, allowing Functions to have fixed independent processing capabilities. <br /><br />**KisSource**: Interface for connecting to ODS data sources. |"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "provides kisflow's timed task, statistics, and aggregation calculation capabilities",
      "normalized_text": "Provides kisflow's timed task, statistics, and aggregation calculation capabilities",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L57",
          "evidence": "| Task Scheduling Layer | Timed task scheduling and execution business logic, including task scheduling platform, executor management, scheduling logs, and user management. Provides KisFlow's timed task, statistics, and aggregation calculation capabilities.  | **The task scheduling platform has a visual interface.**\uff1ancludes running reports, scheduling reports, success rate, task management, configuration management, and GLUE IDE as visual management platforms. <br /><br /> **Executor management KisJobs**: Golang SDK, custom business logic, executor automatic registration, task triggering, termination, and removal.<br /><br /> **Executor scenarios KisScenes**: Logical task sets divided according to business needs.<br /><br /> **Scheduling logs and user management**: Collection of task scheduling logs, detailed scheduling, and scheduling process traces.                                                                              |"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create new function configuration",
      "normalized_text": "Create new function configuration",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L127",
          "evidence": "// Create a new flow configuration"
        },
        {
          "url": "https://github.com/aceld/kis-flow#L130",
          "evidence": "// Create new function configuration"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "create a new flow",
      "normalized_text": "Create a new flow",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/aceld/kis-flow#L134",
          "evidence": "// Create a new flow"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide the entire audio or video file to whisper, which then converts the speech into text",
      "normalized_text": "Provide the entire audio or video file to whisper, which then converts the speech into text",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L15",
          "evidence": "OpenAI [Whisper](https://github.com/openai/whisper) is a versatile speech recognition model designed for general use. Trained on a vast and varied audio dataset, Whisper can handle tasks such as multilingual speech recognition, speech translation, and language identification. It is commonly used for batch transcription, where you provide the entire audio or video file to Whisper, which then converts the speech into text. This process is not done in real-time; instead, Whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "handle tasks such as multilingual speech recognition, speech translation, and language identification",
      "normalized_text": "Handle tasks such as multilingual speech recognition, speech translation, and language identification",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L15",
          "evidence": "OpenAI [Whisper](https://github.com/openai/whisper) is a versatile speech recognition model designed for general use. Trained on a vast and varied audio dataset, Whisper can handle tasks such as multilingual speech recognition, speech translation, and language identification. It is commonly used for batch transcription, where you provide the entire audio or video file to Whisper, which then converts the speech into text. This process is not done in real-time; instead, Whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process is not done in real-time; instead, whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later",
      "normalized_text": "Process is not done in real-time; instead, whisper processes the files and returns the text afterward, similar to han...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L15",
          "evidence": "OpenAI [Whisper](https://github.com/openai/whisper) is a versatile speech recognition model designed for general use. Trained on a vast and varied audio dataset, Whisper can handle tasks such as multilingual speech recognition, speech translation, and language identification. It is commonly used for batch transcription, where you provide the entire audio or video file to Whisper, which then converts the speech into text. This process is not done in real-time; instead, Whisper processes the files and returns the text afterward, similar to handing over a recording and receiving the transcript later."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generate real-time transcriptions for your media content",
      "normalized_text": "Generate real-time transcriptions for your media content",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L18",
          "evidence": "Using Whisper Flow, you can generate real-time transcriptions for your media content. Unlike batch transcriptions, where media files are uploaded and processed, streaming media is delivered to Whisper Flow in real time, and the service returns a transcript immediately."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times",
      "normalized_text": "Include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster...",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L21",
          "evidence": "Streaming content is sent as a series of sequential data packets, or 'chunks,' which Whisper Flow transcribes on the spot. The benefits of using streaming over batch processing include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times. However, this speed may come at the expense of accuracy in some cases."
        },
        {
          "url": "https://github.com/dimastatz/whisper-flow#L21",
          "evidence": "Streaming content is sent as a series of sequential data packets, or 'chunks,' which Whisper Flow transcribes on the spot. The benefits of using streaming over batch processing include the ability to incorporate real-time speech-to-text functionality into your applications and achieving faster transcription times. However, this speed may come at the expense of accuracy in some cases."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "perform operations on data within specific time frames known as temporal windows",
      "normalized_text": "Perform operations on data within specific time frames known as temporal windows",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L24",
          "evidence": "In scenarios involving time-streaming, it's typical to perform operations on data within specific time frames known as temporal windows. One common approach is using the [tumbling window](https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions#tumbling-window) technique, which involves gathering events into segments until a certain condition is met."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run whisperflow as a web server, start by cloning the repository to your local machine",
      "normalized_text": "Run whisperflow as a web server, start by cloning the repository to your local machine",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L98",
          "evidence": "To run WhisperFlow as a web server, start by cloning the repository to your local machine."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a local venv with all dependencies and run the web server on port 8181",
      "normalized_text": "Create a local venv with all dependencies and run the web server on port 8181",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L102",
          "evidence": "Then navigate to WhisperFlow folder, create a local venv with all dependencies and run the web server on port 8181."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run the web server on port 8181",
      "normalized_text": "Run the web server on port 8181",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L102",
          "evidence": "Then navigate to WhisperFlow folder, create a local venv with all dependencies and run the web server on port 8181."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "handle terminate exception to stop the session and close the connection if needed",
      "normalized_text": "Handle terminate exception to stop the session and close the connection if needed",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L111",
          "evidence": "Set up a WebSocket endpoint for real-time transcription by retrieving the transcription model and creating asynchronous functions for transcribing audio chunks and sending JSON responses. Manage the WebSocket connection by continuously processing incoming audio data. Handle terminate exception to stop the session and close the connection if needed."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "manage the websocket connection by continuously processing incoming audio data",
      "normalized_text": "Manage the websocket connection by continuously processing incoming audio data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L111",
          "evidence": "Set up a WebSocket endpoint for real-time transcription by retrieving the transcription model and creating asynchronous functions for transcribing audio chunks and sending JSON responses. Manage the WebSocket connection by continuously processing incoming audio data. Handle terminate exception to stop the session and close the connection if needed."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing incoming audio data",
      "normalized_text": "Processing incoming audio data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L111",
          "evidence": "Set up a WebSocket endpoint for real-time transcription by retrieving the transcription model and creating asynchronous functions for transcribing audio chunks and sending JSON responses. Manage the WebSocket connection by continuously processing incoming audio data. Handle terminate exception to stop the session and close the connection if needed."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "import whsiperflow and transcriber modules",
      "normalized_text": "Import whsiperflow and transcriber modules",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L119",
          "evidence": "Now import whsiperflow and transcriber modules"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "import whisperflow",
      "normalized_text": "Import whisperflow",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L122",
          "evidence": "import whisperflow.streaming as st"
        },
        {
          "url": "https://github.com/dimastatz/whisper-flow#L123",
          "evidence": "import whisperflow.transcriber as ts"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "[X] Release v1.0-RC - Includes transcription streaming implementation.",
      "normalized_text": "[x] release v1.0-rc - includes transcription streaming implementation.",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L147",
          "evidence": "- [X] Release v1.0-RC - Includes transcription streaming implementation."
        },
        {
          "url": "https://github.com/dimastatz/whisper-flow#L147",
          "evidence": "- [X] Release v1.0-RC - Includes transcription streaming implementation."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "[X] Release v1.1 - Bug fixes and implementation of the most requested changes.",
      "normalized_text": "[x] release v1.1 - bug fixes and implementation of the most requested changes.",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/dimastatz/whisper-flow#L148",
          "evidence": "- [X] Release v1.1 - Bug fixes and implementation of the most requested changes."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "handle a diverse",
      "normalized_text": "Handle a diverse",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L10",
          "evidence": "technologies from these companies to create a disruptive new framework to handle a diverse"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a disruptive new framework to handle a diverse",
      "normalized_text": "Create a disruptive new framework to handle a diverse",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L10",
          "evidence": "technologies from these companies to create a disruptive new framework to handle a diverse"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides scalable, reliable, and persistent high-throughput",
      "normalized_text": "Provides scalable, reliable, and persistent high-throughput",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L13",
          "evidence": "Cask Data has built technology that provides scalable, reliable, and persistent high-throughput"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing with high-level java apis using hadoop and hbase",
      "normalized_text": "Processing with high-level java apis using hadoop and hbase",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L14",
          "evidence": "event processing with high-level Java APIs using Hadoop and HBase."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides massively scalable, , and in-memory",
      "normalized_text": "Provides massively scalable, , and in-memory",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L16",
          "evidence": "AT&T has built a streaming engine that provides massively scalable, flexible, and in-memory"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing with a sql-like query language",
      "normalized_text": "Processing with a sql-like query language",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L17",
          "evidence": "low-latency stream processing with a SQL-like query Language."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Ability to handle extremely large data flows;",
      "normalized_text": "Ability to handle extremely large data flows;",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L23",
          "evidence": "- Ability to handle extremely large data flows;"
        },
        {
          "url": "https://github.com/cdapio/tigon#L23",
          "evidence": "- Ability to handle extremely large data flows;"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Exactly-once event processing using an app-level Java API with consistency, reliability, and persistence;",
      "normalized_text": "Exactly-once event processing using an app-level java api with consistency, reliability, and persistence;",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L24",
          "evidence": "- Exactly-once event processing using an app-level Java API with consistency, reliability, and persistence;"
        },
        {
          "url": "https://github.com/cdapio/tigon#L24",
          "evidence": "- Exactly-once event processing using an app-level Java API with consistency, reliability, and persistence;"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "runs collections of queries using pipelined query plans;",
      "normalized_text": "Runs collections of queries using pipelined query plans;",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L26",
          "evidence": "- Runs collections of queries using pipelined query plans;"
        },
        {
          "url": "https://github.com/cdapio/tigon#L26",
          "evidence": "- Runs collections of queries using pipelined query plans;"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Able to transparently handle complex record routing in large parallelized implementations;",
      "normalized_text": "Transparently handle complex record routing in large parallelized implementations;",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L27",
          "evidence": "- Able to transparently handle complex record routing in large parallelized implementations;"
        },
        {
          "url": "https://github.com/cdapio/tigon#L27",
          "evidence": "- Able to transparently handle complex record routing in large parallelized implementations;"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "runs and scales as a native apache hadoop yarn application;",
      "normalized_text": "Runs and scales as a native apache hadoop yarn application;",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L28",
          "evidence": "- Runs and scales as a native Apache Hadoop YARN Application;"
        },
        {
          "url": "https://github.com/cdapio/tigon#L28",
          "evidence": "- Runs and scales as a native Apache Hadoop YARN Application;"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "integrates with hdfs and hbase;",
      "normalized_text": "Integrates with hdfs and hbase;",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L29",
          "evidence": "- Reads, writes, and tightly integrates with HDFS and HBase;"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "supports a significant amount of parallelization;",
      "normalized_text": "Supports a significant amount of parallelization;",
      "category": "Performance",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L30",
          "evidence": "- Supports a significant amount of parallelization;"
        },
        {
          "url": "https://github.com/cdapio/tigon#L30",
          "evidence": "- Supports a significant amount of parallelization;"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "monitoring tools; and",
      "normalized_text": "Monitoring tools; and",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L32",
          "evidence": "- Enterprise security features with debugging, logging, and monitoring tools; and"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run tigon; note that $java_home should be set)",
      "normalized_text": "Run tigon; note that $java_home should be set)",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L56",
          "evidence": "1. JDK 6 or JDK 7 (required to run Tigon; note that $JAVA_HOME should be set)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build the example applications)",
      "normalized_text": "Build the example applications)",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L59",
          "evidence": "4. Apache Maven 3.0+ (required to build the example applications)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run the tigonsql stream engine outside of tigon, libz, perl 5",
      "normalized_text": "Run the tigonsql stream engine outside of tigon, libz, perl 5",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L61",
          "evidence": "Note: To run the TigonSQL Stream Engine outside of Tigon, libz, Perl 5.x, and Python 3.x are required."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run instructions",
      "normalized_text": "Run instructions",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L72",
          "evidence": "### Run Instructions"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run tigon in standalone mode:",
      "normalized_text": "Run tigon in standalone mode:",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L74",
          "evidence": "To run Tigon in standalone mode:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run tigon in distributed mode:",
      "normalized_text": "Run tigon in distributed mode:",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L78",
          "evidence": "To run Tigon in distributed mode:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "building from source",
      "normalized_text": "Building from source",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L82",
          "evidence": "### Building from Source"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build tigon directly from the latest source code:",
      "normalized_text": "Build tigon directly from the latest source code:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L84",
          "evidence": "You can also build Tigon directly from the latest source code:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build completes, you will have a distribution of tigon under the",
      "normalized_text": "Build completes, you will have a distribution of tigon under the",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L90",
          "evidence": "After the build completes, you will have a distribution of Tigon under the"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing framework used in the cask data application platform ([cdap](http://cdap",
      "normalized_text": "Processing framework used in the cask data application platform ([cdap](http://cdap",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L119",
          "evidence": "Tigon is the realtime stream processing framework used in the Cask Data Application Platform ([CDAP](http://cdap.io))."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides a high-level [dataset](http://docs",
      "normalized_text": "Provides a high-level [dataset](http://docs",
      "category": "Documentation",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L120",
          "evidence": "CDAP provides a high-level [Dataset](http://docs.cask.co/cdap/current/en/developers-manual/building-blocks/datasets/index.html) abstraction for User Data Stores"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allows developers to interact with them in their flowlets",
      "normalized_text": "Allows developers to interact with them in their flowlets",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L121",
          "evidence": "and allows developers to interact with them in their flowlets. In addition to the Dataset abstraction, CDAP integrates Batch Processing with"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "integrates batch processing with",
      "normalized_text": "Integrates batch processing with",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L121",
          "evidence": "and allows developers to interact with them in their flowlets. In addition to the Dataset abstraction, CDAP integrates Batch Processing with"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "building phase, similar to apache's",
      "normalized_text": "Building phase, similar to apache's",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L138",
          "evidence": "We have a simple pull-based development model with a consensus-building phase, similar to Apache's"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a topic branch with an appropriate name",
      "normalized_text": "Create a topic branch with an appropriate name",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L146",
          "evidence": "3. Create a topic branch with an appropriate name."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a pull request from your github repo (it\u2019s helpful if you fill in",
      "normalized_text": "Create a pull request from your github repo (it\u2019s helpful if you fill in",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L148",
          "evidence": "5. Once you\u2019re satisfied, create a pull request from your GitHub repo (it\u2019s helpful if you fill in"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "*Tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework.",
      "normalized_text": "*tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L7",
          "evidence": "**Tigon** is an open-source, real-time, low-latency, high-throughput stream processing framework."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Reads, writes, and tightly integrates with HDFS and HBase;",
      "normalized_text": "Reads, writes, and tightly integrates with hdfs and hbase;",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L29",
          "evidence": "- Reads, writes, and tightly integrates with HDFS and HBase;"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Enterprise security features with debugging, logging, and monitoring tools; and",
      "normalized_text": "Enterprise security features with debugging, logging, and monitoring tools; and",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L32",
          "evidence": "- Enterprise security features with debugging, logging, and monitoring tools; and"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Open-source software and development process.",
      "normalized_text": "Open-source software and development process.",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/cdapio/tigon#L34",
          "evidence": "- Open-source software and development process."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build openwrt using github actions",
      "normalized_text": "Build openwrt using github actions",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L7",
          "evidence": "Build OpenWrt using GitHub Actions"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a new repository",
      "normalized_text": "Create a new repository",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L13",
          "evidence": "- Click the [Use this template](https://github.com/P3TERX/Actions-OpenWrt/generate) button to create a new repository."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build starts automatically",
      "normalized_text": "Build starts automatically",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L15",
          "evidence": "- Push `.config` file to the GitHub repository, and the build starts automatically.Progress can be viewed on the Actions page."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "When the build is , click the `Artifacts` button in the upper right corner of the Actions page to download the binaries.",
      "normalized_text": "When the build is , click the `artifacts` button in the upper right corner of the actions page to download the binaries.",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L16",
          "evidence": "- When the build is complete, click the `Artifacts` button in the upper right corner of the Actions page to download the binaries."
        },
        {
          "url": "https://github.com/zszszszsz/.config#L16",
          "evidence": "- When the build is complete, click the `Artifacts` button in the upper right corner of the Actions page to download the binaries."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "create repository to build your own firmware, you may check out if others have already built it which meet your needs by [search `actions-openwrt` in github](https://github",
      "normalized_text": "Create repository to build your own firmware, you may check out if others have already built it which meet your needs...",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L20",
          "evidence": "It may take a long time to create a `.config` file and build the OpenWrt firmware. Thus, before create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `Actions-Openwrt` in GitHub](https://github.com/search?q=Actions-openwrt)."
        },
        {
          "url": "https://github.com/zszszszsz/.config#L20",
          "evidence": "It may take a long time to create a `.config` file and build the OpenWrt firmware. Thus, before create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `Actions-Openwrt` in GitHub](https://github.com/search?q=Actions-openwrt)."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "build the openwrt firmware",
      "normalized_text": "Build the openwrt firmware",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L20",
          "evidence": "It may take a long time to create a `.config` file and build the OpenWrt firmware. Thus, before create repository to build your own firmware, you may check out if others have already built it which meet your needs by simply [search `Actions-Openwrt` in GitHub](https://github.com/search?q=Actions-openwrt)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Click the Use this template button to create a new repository.",
      "normalized_text": "Click the use this template button to create a new repository.",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L13",
          "evidence": "- Click the [Use this template](https://github.com/P3TERX/Actions-OpenWrt/generate) button to create a new repository."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Generate `.config` files using Lean's OpenWrt source code. ( You can change it through environment variables in the workflow file. )",
      "normalized_text": "Generate `.config` files using lean's openwrt source code. ( you can change it through environment variables in the w...",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L14",
          "evidence": "- Generate `.config` files using [Lean's OpenWrt](https://github.com/coolsnowwolf/lede) source code. ( You can change it through environment variables in the workflow file. )"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Push `.config` file to the GitHub repository, and the build starts automatically.Progress can be viewed on the Actions page.",
      "normalized_text": "Push `.config` file to the github repository, and the build starts automatically.progress can be viewed on the action...",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/zszszszsz/.config#L15",
          "evidence": "- Push `.config` file to the GitHub repository, and the build starts automatically.Progress can be viewed on the Actions page."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Processing: Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical.",
      "normalized_text": "Processing: dagger can transform, aggregate, join and enrich streaming data, both real-time and historical.",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L18",
          "evidence": "- **Processing:** Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical."
        },
        {
          "url": "https://github.com/raystack/dagger#L18",
          "evidence": "- **Processing:** Dagger can transform, aggregate, join and enrich streaming data, both real-time and historical."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Scale: Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops.",
      "normalized_text": "Scale: dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero dat...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L19",
          "evidence": "- **Scale:** Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops."
        },
        {
          "url": "https://github.com/raystack/dagger#L19",
          "evidence": "- **Scale:** Dagger scales in an instant, both vertically and horizontally for high performance streaming sink and zero data drops."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Extensibility: Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources.",
      "normalized_text": "Extensibility: add your own sink to dagger with a clearly defined interface or choose from already provided ones. use...",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L20",
          "evidence": "- **Extensibility:** Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources."
        },
        {
          "url": "https://github.com/raystack/dagger#L20",
          "evidence": "- **Extensibility:** Add your own sink to dagger with a clearly defined interface or choose from already provided ones. Use Kafka and/or Parquet Files as stream sources."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Flexibility: Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic.",
      "normalized_text": "Flexibility: add custom business logic in form of plugins \\(udfs, transformers, preprocessors and post processors\\) i...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L21",
          "evidence": "- **Flexibility:** Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic."
        },
        {
          "url": "https://github.com/raystack/dagger#L21",
          "evidence": "- **Flexibility:** Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "Metrics: Always know what\u2019s going on with your deployment with built-in monitoring of throughput, response times, errors and more.",
      "normalized_text": "Metrics: always know what\u2019s going on with your deployment with built-in monitoring of throughput, response times, err...",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L22",
          "evidence": "- **Metrics:** Always know what\u2019s going on with your deployment with built-in [monitoring](https://raystack.github.io/dagger/docs/reference/metrics) of throughput, response times, errors and more."
        },
        {
          "url": "https://github.com/raystack/dagger#L22",
          "evidence": "- **Metrics:** Always know what\u2019s going on with your deployment with built-in [monitoring](https://raystack.github.io/dagger/docs/reference/metrics) of throughput, response times, errors and more."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "processing and analysis on streaming data",
      "normalized_text": "Processing and analysis on streaming data",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L10",
          "evidence": "data as a stream. Instead, you can write SQL queries and UDFs to do the processing and analysis on streaming data."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "plugins \\(udfs, transformers, preprocessors and post processors\\) independent of the core logic",
      "normalized_text": "Plugins \\(udfs, transformers, preprocessors and post processors\\) independent of the core logic",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L21",
          "evidence": "- **Flexibility:** Add custom business logic in form of plugins \\(UDFs, Transformers, Preprocessors and Post Processors\\) independent of the core logic."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "processing -> [longbow](https://raystack",
      "normalized_text": "Processing -> [longbow](https://raystack",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L31",
          "evidence": "- Realtime long window processing -> [Longbow](https://raystack.github.io/dagger/docs/advance/longbow)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides guidance on [creating dagger](https://raystack",
      "normalized_text": "Provides guidance on [creating dagger](https://raystack",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L39",
          "evidence": "- [Guides](https://raystack.github.io/dagger/docs/guides/overview) provides guidance on [creating Dagger](https://raystack.github.io/dagger/docs/guides/create_dagger) with different sinks."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run code quality checks",
      "normalized_text": "Run code quality checks",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L65",
          "evidence": "# Run code quality checks"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build and test your changes to dagger",
      "normalized_text": "Build and test your changes to dagger",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L76",
          "evidence": "Read our [contributing guide](https://raystack.github.io/dagger/docs/contribute/contribution) to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes to Dagger."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Enrichment -> Post Processors",
      "normalized_text": "Enrichment -> post processors",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L27",
          "evidence": "- Enrichment -> [Post Processors](https://raystack.github.io/dagger/docs/advance/post_processor)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Realtime long window processing -> Longbow",
      "normalized_text": "Realtime long window processing -> longbow",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L31",
          "evidence": "- Realtime long window processing -> [Longbow](https://raystack.github.io/dagger/docs/advance/longbow)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Guides provides guidance on creating Dagger with different sinks.",
      "normalized_text": "Guides provides guidance on creating dagger with different sinks.",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L39",
          "evidence": "- [Guides](https://raystack.github.io/dagger/docs/guides/overview) provides guidance on [creating Dagger](https://raystack.github.io/dagger/docs/guides/create_dagger) with different sinks."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Concepts describes all important Dagger concepts.",
      "normalized_text": "Concepts describes all important dagger concepts.",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L40",
          "evidence": "- [Concepts](https://raystack.github.io/dagger/docs/concepts/overview) describes all important Dagger concepts."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "*Note:** Sample configuration for running a basic dagger can be found here. For detailed configurations, refer here.",
      "normalized_text": "*note:** sample configuration for running a basic dagger can be found here. for detailed configurations, refer here.",
      "category": "Configuration",
      "sources": [
        {
          "url": "https://github.com/raystack/dagger#L51",
          "evidence": "**Note:** Sample configuration for running a basic dagger can be found [here](https://raystack.github.io/dagger/docs/guides/create_dagger#common-configurations). For detailed configurations, refer [here](https://raystack.github.io/dagger/docs/reference/configuration)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process has to do with finding or creating the right (annotated) dataset",
      "normalized_text": "Process has to do with finding or creating the right (annotated) dataset",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L3",
          "evidence": "This repo documents steps and scripts used to train a hand detector using Tensorflow (Object Detection API). As with any DNN based task, the most expensive (and riskiest) part of the process has to do with finding or creating the right (annotated) dataset. I was interested mainly in detecting hands on a table (egocentric view point). I experimented first with the [Oxford Hands Dataset](http://www.robots.ox.ac.uk/~vgg/data/hands/) (the results were not good). I then tried the [Egohands Dataset](http://vision.soic.indiana.edu/projects/egohands/) which was a much better fit to my requirements."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide code that can be adapted to other uses cases",
      "normalized_text": "Provide code that can be adapted to other uses cases",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L5",
          "evidence": "The goal of this repo/post is to demonstrate how neural networks can be applied to the (hard) problem of tracking hands (egocentric and other views). Better still, provide code that can be adapted to other uses cases."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "tracking hands (egocentric and other views)",
      "normalized_text": "Tracking hands (egocentric and other views)",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L5",
          "evidence": "The goal of this repo/post is to demonstrate how neural networks can be applied to the (hard) problem of tracking hands (egocentric and other views). Better still, provide code that can be adapted to other uses cases."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run on a macbook pro cpu (i7, 2",
      "normalized_text": "Run on a macbook pro cpu (i7, 2",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L17",
          "evidence": "Both examples above were run on a macbook pro **CPU** (i7, 2.5GHz, 16GB). Some fps numbers are:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run without visualizing results|",
      "normalized_text": "Run without visualizing results|",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L22",
          "evidence": "| 21  | 320 * 240  | Macbook pro (i7, 2.5GHz, 16GB) | Run without visualizing results|"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run while visualizing results (image above) |",
      "normalized_text": "Run while visualizing results (image above) |",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L23",
          "evidence": "| 16  | 320 * 240  | Macbook pro (i7, 2.5GHz, 16GB) | Run while visualizing results (image above) |"
        },
        {
          "url": "https://github.com/molyswu/hand_detection#L24",
          "evidence": "| 11  | 640 * 480  | Macbook pro (i7, 2.5GHz, 16GB) | Run while visualizing results (image above) |"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "generate your own frozen model](https://pythonprogramming",
      "normalized_text": "Generate your own frozen model](https://pythonprogramming",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L27",
          "evidence": "You may need to [generate your own frozen model](https://pythonprogramming.net/testing-custom-object-detector-tensorflow-object-detection-api-tutorial/?completed=/training-custom-objects-tensorflow-object-detection-api-tutorial/) graph using the [model checkpoints](model-checkpoint) in the repo to fit your TF version."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "tracking hands in the computer vision domain",
      "normalized_text": "Tracking hands in the computer vision domain",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L42",
          "evidence": "There are several existing approaches to tracking hands in the computer vision domain. Incidentally, many of these approaches are rule based (e.g extracting background based on texture and boundary features, distinguishing between hands and background using color histograms and HOG classifiers,) making them not very robust. For example, these algorithms might get confused if the background is unusual or in situations where sharp changes in lighting conditions cause sharp changes in skin color or the tracked object becomes occluded.(see [here for a review](https://www.cse.unr.edu/~bebis/handposerev.pdf) paper on hand pose estimation from the HCI perspective)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion",
      "normalized_text": "Provide opportunity to train models that perform well and address challenges of existing object tracking/detection al...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L44",
          "evidence": "With sufficiently large datasets, neural networks provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion. The main drawbacks to usage for real-time tracking/detection is that they can be complex, are relatively slow compared to tracking-only algorithms and it can be quite expensive to assemble a good dataset. But things are changing with advances in fast neural networks."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion",
      "normalized_text": "Perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy en...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L44",
          "evidence": "With sufficiently large datasets, neural networks provide opportunity to train models that perform well and address challenges of existing object tracking/detection algorithms - varied/poor lighting, noisy environments, diverse viewpoints and even occlusion. The main drawbacks to usage for real-time tracking/detection is that they can be complex, are relatively slow compared to tracking-only algorithms and it can be quite expensive to assemble a good dataset. But things are changing with advances in fast neural networks."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process of training a model for custom object detection",
      "normalized_text": "Process of training a model for custom object detection",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L46",
          "evidence": "Furthermore, this entire area of work has been made more approachable by deep learning frameworks (such as the tensorflow object detection api) that simplify the process of training a model for custom object detection. More importantly, the advent of fast neural network models like ssd, faster r-cnn, rfcn (see [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models) ) etc make neural networks an attractive candidate for real-time detection (and tracking) applications. Hopefully, this repo demonstrates this."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provide in detecting hands](#detecting-hands)",
      "normalized_text": "Provide in detecting hands](#detecting-hands)",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L48",
          "evidence": "> If you are not interested in the process of training the detector, you can skip straight to applying the [pretrained model I provide in detecting hands](#detecting-hands)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process of training the detector, you can skip straight to applying the pretrained model i provide in detecting hands",
      "normalized_text": "Process of training the detector, you can skip straight to applying the pretrained model i provide in detecting hands",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L48",
          "evidence": "> If you are not interested in the process of training the detector, you can skip straight to applying the [pretrained model I provide in detecting hands](#detecting-hands)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process (assembling dataset, cleaning, splitting into training/test partitions and generating an inference graph)",
      "normalized_text": "Process (assembling dataset, cleaning, splitting into training/test partitions and generating an inference graph)",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L50",
          "evidence": "Training a model is a multi-stage process (assembling dataset, cleaning, splitting into training/test partitions and generating an inference graph). While I lightly touch on the details of these parts, there are a few other tutorials cover training a custom object detector using the tensorflow object detection api in more detail[ see [here](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) and [here](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9) ]. I recommend you walk through those if interested in training a custom object detector from scratch."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generate these csv files",
      "normalized_text": "Generate these csv files",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L82",
          "evidence": "Some initial work needs to be done to the Egohands dataset to transform it into the format (`tfrecord`) which Tensorflow needs to train a model. This repo contains `egohands_dataset_clean.py` a script that will help you generate these csv files."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Renames all files to include their directory names to ensure each filename is unique",
      "normalized_text": "Renames all files to include their directory names to ensure each filename is unique",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L85",
          "evidence": "- Renames all files to include their directory names to ensure each filename is unique"
        },
        {
          "url": "https://github.com/molyswu/hand_detection#L85",
          "evidence": "- Renames all files to include their directory names to ensure each filename is unique"
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "generates bounding boxes and visualizes them to ensure correctness (see image above)",
      "normalized_text": "Generates bounding boxes and visualizes them to ensure correctness (see image above)",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L87",
          "evidence": "- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above)."
        },
        {
          "url": "https://github.com/molyswu/hand_detection#L87",
          "evidence": "- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above)."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "generate `tfrecords`",
      "normalized_text": "Generate `tfrecords`",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L88",
          "evidence": "- Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv`  that can be used to generate `tfrecords`"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "support 4 labels",
      "normalized_text": "Support 4 labels",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L90",
          "evidence": "Note: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, i am only interested in the general `hand` class and label all training data as `hand`",
      "normalized_text": "Provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, i am only...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L90",
          "evidence": "Note: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generate `tfrecords` that support 4 labels",
      "normalized_text": "Generate `tfrecords` that support 4 labels",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L90",
          "evidence": "Note: While the egohands dataset provides four separate labels for hands (own left, own right, other left, and other right), for my purpose, I am only interested in the general `hand` class and label all training data as `hand`. You can modify the data prep script to generate `tfrecords` that support 4 labels."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generate `train",
      "normalized_text": "Generate `train",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L92",
          "evidence": "Next: convert your dataset + csv files to tfrecords. A helpful guide on this can be found [here](https://pythonprogramming.net/creating-tfrecord-files-tensorflow-object-detection-api-tutorial/).For each folder, you should be able to generate  `train.record`, `test.record` required in the training process."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "offer a few models (in the tensorflow [model zoo](https://github",
      "normalized_text": "Offer a few models (in the tensorflow [model zoo](https://github",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process called [transfer learning](https://www",
      "normalized_text": "Process called [transfer learning](https://www",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process can be done locally on your cpu machine which may take a while or better on a (cloud) gpu machine (which is what i did)",
      "normalized_text": "Process can be done locally on your cpu machine which may take a while or better on a (cloud) gpu machine (which is w...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run 200k steps on my mac (i7, 2",
      "normalized_text": "Run 200k steps on my mac (i7, 2",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L97",
          "evidence": "Now that the dataset has been assembled (and your tfrecords), the next task is to train a model based on this. With neural networks, it is possible to use a process called [transfer learning](https://www.tensorflow.org/tutorials/image_retraining) to shorten the amount of time needed to train the entire model. This means we can take an existing model (that has been trained well on a related domain (here image classification) and retrain its final layer(s) to detect hands for us. Sweet!. Given that neural networks sometimes have thousands or millions of parameters that can take weeks or months to train, transfer learning helps shorten training time to possibly hours. Tensorflow does offer a few models (in the tensorflow [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models-coco-models)) and I chose to use the `ssd_mobilenet_v1_coco` model as my start point given it is currently (one of) the fastest models (read the SSD research [paper here](https://arxiv.org/pdf/1512.02325.pdf)). The training process can be done locally on your CPU machine which may take a while or better on a (cloud) GPU machine (which is what I did). For reference, training on my macbook pro (tensorflow compiled from source to take advantage of the mac's cpu architecture) the maximum speed I got was 5 seconds per step as opposed to the ~0.5 seconds per step I got with a GPU. For reference it would take about 12 days to run 200k steps on my mac (i7, 2.5GHz, 16GB) compared to ~5hrs on a GPU."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process if training locally",
      "normalized_text": "Process if training locally",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L99",
          "evidence": "> **Training on your own images**: Please use the [guide provided by Harrison from pythonprogramming](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) on how to generate tfrecords given your label csv files and your images. The guide also covers how to start the training process if training locally. [see [here] (https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/)]. If training in the cloud using a service like GCP, see the [guide here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generate tfrecords given your label csv files and your images",
      "normalized_text": "Generate tfrecords given your label csv files and your images",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L99",
          "evidence": "> **Training on your own images**: Please use the [guide provided by Harrison from pythonprogramming](https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/) on how to generate tfrecords given your label csv files and your images. The guide also covers how to start the training process if training locally. [see [here] (https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/)]. If training in the cloud using a service like GCP, see the [guide here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_cloud.md)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout)",
      "normalized_text": "Process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value o...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process is (total loss does not decrease with further iterations/steps)",
      "normalized_text": "Process is (total loss does not decrease with further iterations/steps)",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset",
      "normalized_text": "Generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run an evaluation concurrently that assesses your model to see how well it performs on the test data",
      "normalized_text": "Run an evaluation concurrently that assesses your model to see how well it performs on the test data",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "performs on the test data",
      "normalized_text": "Performs on the test data",
      "category": "Developer Tools",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L101",
          "evidence": "As the training process progresses, the expectation is that total loss (errors) gets reduced to its possible minimum (about a value of 1 or thereabout). By observing the tensorboard graphs for total loss(see image below), it should be possible to get an idea of when the training process is complete (total loss does not decrease with further iterations/steps). I ran my training job for 200k steps (took about 5 hours) and stopped at a total Loss (errors) value of 2.575.(In retrospect, I could have stopped the training at about 50k steps and gotten a similar total loss value). With tensorflow, you can also run an evaluation concurrently that assesses your model to see how well it performs on the test data. A commonly used metric for performance is mean average precision (mAP) which is single number used to summarize the area under the precision-recall curve.  mAP is a measure of how well the model generates a bounding box that has at least a 50% overlap with the ground truth bounding box in our test dataset. For the hand detector trained here, the mAP value was **0.9686@0.5IOU**. mAP values range from 0-1, the higher the better."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "visualize detected bounding detection_boxes",
      "normalized_text": "Visualize detected bounding detection_boxes",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L132",
          "evidence": "- Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc",
      "normalized_text": "Visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L137",
          "evidence": "- detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run detection on video at path \"videos/chess",
      "normalized_text": "Run detection on video at path \"videos/chess",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L142",
          "evidence": "# load and run detection on video at path \"videos/chess.mov\""
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "generate a new graph that fits your tf version from the model-checkpoint in this repo",
      "normalized_text": "Generate a new graph that fits your tf version from the model-checkpoint in this repo",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L146",
          "evidence": "> Update: If you do have errors loading the frozen inference graph in this repo, feel free to generate a new graph that fits your TF version from the model-checkpoint in this repo."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "run on the main application thread can slow down the program",
      "normalized_text": "Run on the main application thread can slow down the program",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L153",
          "evidence": "- Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from [Adrian Rosebuck](https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/) on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "tracking algorithms with the already decent detection and this is something i am still experimenting with",
      "normalized_text": "Tracking algorithms with the already decent detection and this is something i am still experimenting with",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L162",
          "evidence": "Performance can also be increased by a clever combination of tracking algorithms with the already decent detection and this is something I am still experimenting with. Have ideas for optimizing better, please share!"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "includes non-egocentric viewpoints, very noisy backgrounds (e",
      "normalized_text": "Includes non-egocentric viewpoints, very noisy backgrounds (e",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L165",
          "evidence": "Note: The detector does reflect some limitations associated with the training set. This includes non-egocentric viewpoints, very noisy backgrounds (e.g in a sea of hands) and sometimes skin tone.  There is opportunity to improve these with additional data."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects",
      "normalized_text": "Integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L170",
          "evidence": "One way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "process of assembling datasets for each class and a lengthy training process",
      "normalized_text": "Process of assembling datasets for each class and a lengthy training process",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L170",
          "evidence": "One way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process",
      "normalized_text": "Create a detector that classifies multiple different objects would mean a long involved process of assembling dataset...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L170",
          "evidence": "One way to make things more interesting is to integrate our new knowledge of where \"hands\" are with other detectors trained to recognize other objects. Unfortunately, while our hand detector can in fact detect hands, it cannot detect other objects (a factor or how it is trained). To create a detector that classifies multiple different objects would mean a long involved process of assembling datasets for each class and a lengthy training process."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allow us efficiently interleave output form multiple pretrained models for various object classes and have them detect multiple objects on a single image",
      "normalized_text": "Allow us efficiently interleave output form multiple pretrained models for various object classes and have them detec...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L172",
          "evidence": "> Given the above, a potential strategy is to explore structures that allow us **efficiently** interleave output form multiple pretrained models for various object classes and have them detect multiple objects on a single image."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Motivation - Why Track/Detect hands with Neural Networks",
      "normalized_text": "Motivation - why track/detect hands with neural networks",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L32",
          "evidence": "- Motivation - Why Track/Detect hands with Neural Networks"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Data preparation and network training in Tensorflow (Dataset, Import, Training)",
      "normalized_text": "Data preparation and network training in tensorflow (dataset, import, training)",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L33",
          "evidence": "- Data preparation and network training in Tensorflow (Dataset, Import, Training)"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Using the Detector to Detect/Track hands",
      "normalized_text": "Using the detector to detect/track hands",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L35",
          "evidence": "- Using the Detector to Detect/Track hands"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above).",
      "normalized_text": "Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see imag...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L87",
          "evidence": "- Reads in `polygons.mat` for each folder, generates bounding boxes and visualizes them to ensure correctness (see image above)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv` that can be used to generate `tfrecords`",
      "normalized_text": "Once the script is done running, you should have an images folder containing three folders - train, test and eval. ea...",
      "category": "Automation & AI",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L88",
          "evidence": "- Once the script is done running, you should have an images folder containing three folders - train, test and eval. Each of these folders should also contain a csv label document each - `train_labels.csv`, `test_labels.csv`  that can be used to generate `tfrecords`"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method.",
      "normalized_text": "Visualize detected bounding detection_boxes. in this repo, this is done in the `utils/detector_utils.py` script by th...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L132",
          "evidence": "- Visualize detected bounding detection_boxes. In this repo, this is done in the `utils/detector_utils.py` script by the `draw_box_on_image` method."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc.",
      "normalized_text": "Detect_multi_threaded.py : a threaded implementation for reading camera video input detection and detecting. takes a ...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L137",
          "evidence": "- detect_multi_threaded.py : A threaded implementation for reading camera video input detection and detecting. Takes a set of command line flags to set parameters such as `--display` (visualize detections), image parameters `--width` and `--height`, videe `--source` (0 for camera) etc."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from Adrian Rosebuck on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points.",
      "normalized_text": "Threading: turns out that reading images from a webcam is a heavy i/o event and if run on the main application thread...",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L153",
          "evidence": "- Threading: Turns out that reading images from a webcam is a heavy I/O event and if run on the main application thread can slow down the program. I implemented some good ideas from [Adrian Rosebuck](https://www.pyimagesearch.com/2017/02/06/faster-video-file-fps-with-cv2-videocapture-and-opencv/) on parrallelizing image capture across multiple worker threads. This mostly led to an FPS increase of about 5 points."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "Keeping your input image small will increase fps without any significant accuracy drop.(I used about 320 x 240 compared to the 1280 x 720 which my webcam provides).",
      "normalized_text": "Keeping your input image small will increase fps without any significant accuracy drop.(i used about 320 x 240 compar...",
      "category": "Uncategorized",
      "sources": [
        {
          "url": "https://github.com/molyswu/hand_detection#L158",
          "evidence": "- Keeping your input image small will increase fps without any significant accuracy drop.(I used about 320 x 240 compared to the 1280 x 720 which my webcam provides)."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "allows you to create virtually any graph processing system imaginable",
      "normalized_text": "Allows you to create virtually any graph processing system imaginable",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cross-platform/dspatch#L9",
          "evidence": "DSPatch, pronounced \"dispatch\", is a powerful C++ dataflow framework. DSPatch is not limited to any particular domain or data type, from reactive programming to stream processing, DSPatch's generic, object-oriented API allows you to create virtually any graph processing system imaginable."
        },
        {
          "url": "https://github.com/cross-platform/dspatch#L9",
          "evidence": "DSPatch, pronounced \"dispatch\", is a powerful C++ dataflow framework. DSPatch is not limited to any particular domain or data type, from reactive programming to stream processing, DSPatch's generic, object-oriented API allows you to create virtually any graph processing system imaginable."
        }
      ],
      "frequency": 2,
      "uniqueness_score": 0.5
    },
    {
      "text": "processing system imaginable",
      "normalized_text": "Processing system imaginable",
      "category": "Core Functionality",
      "sources": [
        {
          "url": "https://github.com/cross-platform/dspatch#L9",
          "evidence": "DSPatch, pronounced \"dispatch\", is a powerful C++ dataflow framework. DSPatch is not limited to any particular domain or data type, from reactive programming to stream processing, DSPatch's generic, object-oriented API allows you to create virtually any graph processing system imaginable."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build it into your own projects, all you'll need are the files under `include`",
      "normalized_text": "Build it into your own projects, all you'll need are the files under `include`",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cross-platform/dspatch#L22",
          "evidence": "DSPatch is a header-only library, to build it into your own projects, all you'll need are the files under `include`."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "build the tests and tutorial projects:",
      "normalized_text": "Build the tests and tutorial projects:",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cross-platform/dspatch#L24",
          "evidence": "To build the tests and tutorial projects:"
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    },
    {
      "text": "building dspatch circuits",
      "normalized_text": "Building dspatch circuits",
      "category": "User Interface",
      "sources": [
        {
          "url": "https://github.com/cross-platform/dspatch#L35",
          "evidence": "DSPatcher (https://github.com/cross-platform/dspatcher): A cross-platform graphical tool for building DSPatch circuits."
        }
      ],
      "frequency": 1,
      "uniqueness_score": 1.0
    }
  ],
  "categories": {
    "Integration & APIs": 16,
    "Uncategorized": 114,
    "Automation & AI": 32,
    "Core Functionality": 96,
    "Documentation": 3,
    "User Interface": 39,
    "Developer Tools": 19,
    "Configuration": 10,
    "Security & Privacy": 3,
    "Performance": 8
  }
}